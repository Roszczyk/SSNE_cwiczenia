{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "aF7NhtuRuj3m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQk7qP3Wszsx",
        "outputId": "e2886aed-b03b-49eb-c449-1ae71b907a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlL-F0T8ujBn",
        "outputId": "1a4b6db9-209f-40ee-ca3b-b03d1f62e8d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/train.pkl', 'rb') as f:\n",
        "    data_set = pickle.load(f)"
      ],
      "metadata": {
        "id": "HRKMm6B2uwFd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dz5vfxHvMmg",
        "outputId": "0bf5f3b8-0f00-4aa5-d6a4-2d362ae17003"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "targets = []\n",
        "for i in data_set:\n",
        "  data.append(i[0])\n",
        "  targets.append(i[1])"
      ],
      "metadata": {
        "id": "viCp1NWgEI53"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_array = np.array(targets)\n",
        "targets_array_reshaped = targets_array.reshape(-1, 1)\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "ohe.fit(targets_array_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "x-GkoyTUrksk",
        "outputId": "903a436c-01e4-4949-b458-10487766d768"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneHotEncoder(handle_unknown='ignore', sparse_output=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets_ohe = ohe.transform(targets_array_reshaped)\n",
        "print(targets_ohe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52b_-RYisjYn",
        "outputId": "535af3bb-b704-441f-9eec-48d1a32908b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[-1])\n",
        "print(targets[-1])\n",
        "print(targets_ohe[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6eNqA5MIIcl",
        "outputId": "c96d1f2b-dbf3-46de-a564-335893d708dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[112. 112.   0.  64.   0. 112.  34. 144. 146. 112. 112. 179. 112. 112.\n",
            "  73.   3.  12. 112. 146.  60.  45. 112.  73.  88. 117.   8. 159. 145.\n",
            " 159. 112.  13.  80.  92. 159. 190. 112. 185. 190.   8.  73. 125.  77.\n",
            "  12.   0. 117. 190. 185. 112. 125. 125.  45.  41.  92.  28.  92.  12.\n",
            " 159.   0.  47.  12.  12.  88.  88.   0.  12. 112. 159.   8. 159.   0.\n",
            "  12. 112. 125.  23.  47.  41. 159. 112.  45.  12.   8. 145.  47.  33.\n",
            "  33.  33. 125.  73.   8.  13.  92.  88. 159. 120. 124. 185. 185.  77.\n",
            " 125.  88.  13. 120. 120. 112. 112. 112. 159. 172.  12. 117.  47.  88.\n",
            "  88.  36.  92.  33. 125.  88.  88.  88.  12. 112. 159.  88. 125. 119.\n",
            "  47.  88.  92. 159. 185. 112.  77.  33. 125.  65. 125.  33. 125.  88.\n",
            "  13. 120. 124. 112.  12.   0.   0.   0.  12. 112. 159. 145.   5.   0.\n",
            "  88. 112.  12.  47.  88.   0.  12. 112. 159. 145.   5.   0.  12. 112.\n",
            " 125. 125.  28. 159.  28.  38.  12. 117.  47. 114. 153.  88. 159.   8.\n",
            "   8. 112.  77.  38.  12.   0. 117. 190. 185. 112.  77.  33.  41. 145.\n",
            " 145. 106. 124. 112.  74.  41.  92.  88.  12. 112.  74.  41.  13. 117.\n",
            "  92.  80. 125. 185. 190. 114. 112. 112. 159.  88.  13.   8.  12. 117.\n",
            "  12. 125. 124. 106. 159. 112. 112. 112. 112. 112.  12.   0. 117. 190.\n",
            " 185. 112. 112. 112. 112. 112.]\n",
            "4\n",
            "[0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "labels = [label for _, label in data_set]\n",
        "\n",
        "class_counts = Counter(labels)\n",
        "classes = []\n",
        "print(\"Liczba klas:\", len(class_counts))\n",
        "for class_label, count in class_counts.items():\n",
        "    classes.append(count)\n",
        "classes = np.array(classes)\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "6xQID-J53J_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16eb52d-9226-48c5-ffbd-a3aa63323694"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba klas: 5\n",
            "[1630  478  154  441  236]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target"
      ],
      "metadata": {
        "id": "JTnWdmaG49BT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = np.random.rand(len(data_set))>0.3"
      ],
      "metadata": {
        "id": "5JUCzIp8O5NX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices"
      ],
      "metadata": {
        "id": "Bai0Mly3O9Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7b0f7c-a850-4e93-ed69-16f2738f4ab2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ...,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = []\n",
        "targets_train = []\n",
        "data_test = []\n",
        "targets_test = []\n",
        "for i in range(len(data_set)):\n",
        "  if train_indices[i] == True:\n",
        "    data_train.append(data_set[i][0])\n",
        "    targets_train.append(targets_ohe[i])\n",
        "  else:\n",
        "    data_test.append(data_set[i][0])\n",
        "    targets_test.append(targets_ohe[i])"
      ],
      "metadata": {
        "id": "3gDvCohVPFh-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_size = len(data_set)\n",
        "\n",
        "# train_size = int(0.8 * dataset_size)\n",
        "# test_size = dataset_size - train_size\n",
        "\n",
        "\n",
        "# train_set = VariableLenDataset(data[:train_indices], targets[:train_indices])\n",
        "# test_set = VariableLenDataset(data[train_indices:], targets[train_indices:])"
      ],
      "metadata": {
        "id": "qGbQf80xGZbU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = VariableLenDataset(data_train, targets_train)\n",
        "test_set = VariableLenDataset(data_test, targets_test)"
      ],
      "metadata": {
        "id": "05cbXnJZMV_M"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set[2])"
      ],
      "metadata": {
        "id": "_gSWK_fJK6EO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a0b44e-1555-40bd-9b38-98171780d4a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 66., 100., 148., 148., 146.,  64., 146., 148.,  82.,   0.,  82.,\n",
            "       100.,  34., 132., 180.,  65.,  80.,  81., 131.,  52.,  34.,  52.,\n",
            "        64.,  52.,   3.,  66., 147.,  20.,   4., 132., 132., 100., 111.,\n",
            "        74., 110.,  60.,  92.,  65., 100., 189.,  44.,   8.,   5.,  76.,\n",
            "        31., 159.,   5., 124.,   4.,  12.,  51., 157.,  57.,  31., 183.,\n",
            "        57.,  65.,  92.,  69., 124., 122.,  79., 110.,  76.,  12.,  12.,\n",
            "        12.,  12.,   8., 159.,  12., 156., 100., 111.,  52., 121.,  36.,\n",
            "        47.,  41.,  41.,   8., 172.,  38.,  12.,  78.,  12.,  88.,  47.,\n",
            "       119.,  20.,  47.,  12., 159.,  20.,  20.,  76.,  60., 110., 132.,\n",
            "       185., 120.,  45., 110., 110.,  72., 124., 178.,  73.,   8.,  78.,\n",
            "        12.,  42., 173.,  12., 150.,  84.,  66., 152.,  69.,   8.,  41.,\n",
            "       159.,   5.,  78.,  44., 180.,  71.,  92., 152.,   6.,  12.,  45.,\n",
            "        92., 125.,   8., 156.,  12.,  12., 146.,   8., 185.,   0.,  88.,\n",
            "        92.,  90.,  12.,  12.,  12.,  78.,  92.,   3.,  45., 111., 111.,\n",
            "        71., 137.,  69.,  12.,  88.,  12.,  10.,   8., 172., 156., 152.,\n",
            "       100.,  12.,  12.,  77.,  52., 156., 148.,  12.,  12., 132.,   6.,\n",
            "         6., 185.,  47., 121.,  20.,  90.,  64., 111.,  92., 111.,  77.,\n",
            "        76.,  69., 100.,   8.,  76.,  76.,  69., 132.,   6.,   6.,   8.,\n",
            "        20.,  73.,  77., 111.,   6.,   8.,  13.,  12., 178.,   5.,  88.,\n",
            "       159., 121.,  58.,  44.,  47., 100., 156.,  12.,  41.,  88.,  73.,\n",
            "        20., 125.,  12., 124.,   5.,   0.,   5.,  47.,  12.,  12.,  12.,\n",
            "        12.,   8., 159., 185., 124., 100., 111.,  52., 121.,  36.,  47.,\n",
            "        41.,  41., 180.,   8.,  66.,   8., 146., 180.,  88.,  47., 119.,\n",
            "        20.,  73., 172., 158.,  20.,  20.,  20.,  78.,  69.,  12.,  12.,\n",
            "        47.,  47.,  47.,  30.,   8.,   6.,  45.,  12., 111., 111.,  38.,\n",
            "        12.,  12.,  12., 148.,   6.,   6., 185.,  47., 121.,  20.,  78.,\n",
            "        64., 111.,  77., 111.,  77.,  76., 141., 100.,   8.,  76.,  76.,\n",
            "         6., 132., 100., 111.,  74., 110.,  60., 159.,  79.,   5., 189.,\n",
            "       110.,  12.,   5.,  76.,  10.,  92.,   5., 124.,   4.,  12.,  51.,\n",
            "       157.,  57.,  31., 183.,  57.,  65.,  92.,  69., 124., 122.,  79.,\n",
            "       110.,  76.,  10.,  12.,  12.,  12.,   8., 159.,  12., 156., 100.,\n",
            "       111.,  52., 121.,  36.,  47.,  41.,  41.,   8., 172.,  38.,  12.,\n",
            "        78.,  12.,  88.,  47., 119.,  20.,  47.,  12.,  12.,  78.,  63.,\n",
            "        76.,  60., 110., 159., 132., 124.,  12.,  15., 110., 110.,  72.,\n",
            "       124., 178.,  73.,   8.,  78.,  12.,  12.,  30.,  12., 150.,  84.,\n",
            "        66., 152.,  69.,   8.,  41., 159.,   5.,  78.,  44., 180.,  71.,\n",
            "        92., 156., 132.,  79.,  45.,  92., 125.,   8., 156.,  12.,  12.,\n",
            "       146.,  12., 185.,   0.,  92., 108.,  90.,  47.,  12.,  12., 125.,\n",
            "        92.,   3.,  45., 111., 111.,  71., 137.,  69.,  12.,  47.,  12.,\n",
            "        10.,   8.,  41., 156., 152., 100.,  12.,  12.,  74.,  52., 156.,\n",
            "       148., 148.,  12.,  69.,   6.,   6., 185.,  47., 121.,  20.,  90.,\n",
            "        64., 111.,  92., 111.,  77.,  76., 141., 100.,   8.,  76.,  76.,\n",
            "        69., 132., 100.,   6.,   8.,  88.,  47., 141.,  77.,   6.,   8.,\n",
            "       152.,  12., 178.,   5.,  88., 159., 121.,  58.,  44.,  47., 100.,\n",
            "       156.,  12.,  41.,  88.,  73.,  20., 125.,  12., 124.,   5.,   0.,\n",
            "         5.,  47.,  12.,  12.,  12.,  12.,  12., 159., 185., 124.,   6.,\n",
            "       111.,  52., 121.,  36.,  47.,  41.,  41., 180.,   8.,  66.,   8.,\n",
            "       146., 180.,  88.,  47., 119.,  20.,  73.,  12., 158.,  20.,  20.,\n",
            "        20.,  78.,  69.,  12.,  12.,  47.,  47.,  47., 125.,   8.,   6.,\n",
            "        12.,  12., 111., 111.,  38.,  12.,  12.,  12.,  82.,   6.,   6.,\n",
            "       185.,  47., 121.,  88.,  90.,  64., 111.,  92., 111.,  77.,  76.,\n",
            "       141., 100.,   8.,  76.,  76.,  69., 132.,   6.,   6.,   8.,  47.,\n",
            "        47.,  10.,  10.,  82.,   8., 148.,  38.,  50.,  50.,  34.,  34.,\n",
            "        34.,  34.,  34.,  34., 144., 144., 144., 144.,  -1.]), array([1., 0., 0., 0., 0.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad = -100\n",
        "\n",
        "# def pad_collate(batch, pad_value=pad):\n",
        "#     xx, yy = zip(*batch)\n",
        "#     xx = [torch.tensor(x) for x in xx]\n",
        "#     x_lens = [len(x) for x in xx]\n",
        "#     yy_pad = torch.tensor(yy)\n",
        "#     y_lens = [1] * len(yy)\n",
        "#     # print(xx)\n",
        "#     # print(yy)\n",
        "\n",
        "#     xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "#     # yy_pad = pad_sequence(yy, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "#     return xx_pad, yy_pad, x_lens, y_lens\n",
        "\n",
        "def pad_collate(batch, pad_value=pad):\n",
        "    try:\n",
        "        xx, yy = zip(*batch)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error while unpacking batch: {e}\")\n",
        "        print(f\"Batch content: {batch}\")\n",
        "        raise\n",
        "\n",
        "    xx = [torch.tensor(x) for x in xx]\n",
        "    x_lens = [len(x) for x in xx]\n",
        "    yy_pad = torch.tensor(yy)\n",
        "    y_lens = [1] * len(yy)\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy_pad, x_lens, y_lens"
      ],
      "metadata": {
        "id": "gT4DVyAfws-7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "xBcnjNFqIn6H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_size = len(data)\n",
        "\n",
        "# train_size = int(0.8 * dataset_size)\n",
        "# test_size = dataset_size - train_size\n",
        "\n",
        "# train_set, test_set = random_split(data, [train_size, test_size])\n",
        "\n",
        "# batch_size=4\n",
        "# trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
        "# testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "nE3dVfPevMd-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set[0]\n"
      ],
      "metadata": {
        "id": "n4cE0wPFIndl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5ec8c5-4235-448f-fa9a-b2ddcfec9bb3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ -1.,  -1.,  -1., ...,  78.,  40., 144.]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_set[0][0]))\n",
        "print(len(train_set[1][0]))"
      ],
      "metadata": {
        "id": "8iAC0VKIw776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85a3ac4-c7cb-444c-dd0a-ade9cdef2c32"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4756\n",
            "5322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R2Ulv0AxYvE",
        "outputId": "182c7a2d-8fd0-42c8-d3f3-9901b9441c4d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-76b5b91029d1>:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  yy_pad = torch.tensor(yy)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  80.,  162.,   33.,  ...,  111.,  137.,   64.],\n",
              "         [  -1.,   -1.,  144.,  ..., -100., -100., -100.],\n",
              "         [  -1.,   -1.,   -1.,  ..., -100., -100., -100.],\n",
              "         [ 144.,    8.,  190.,  ..., -100., -100., -100.]], dtype=torch.float64),\n",
              " tensor([[0., 0., 0., 0., 1.],\n",
              "         [1., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0.]], dtype=torch.float64),\n",
              " [308, 288, 68, 270],\n",
              " [1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(320, out_size)\n",
        "        # self.fc = nn.Linear(hidden_size*90*self.bidirectional, out_size)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x = torch.transpose(x,0,1)\n",
        "        x = x.float()\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        # all_outputs = torch.transpose(all_outputs,0,1)\n",
        "        # out = torch.flatten(all_outputs,1)\n",
        "        # output, _ = pad_packed_sequence(all_outputs, batch_first=True)\n",
        "        # output = output[:, -1, :]\n",
        "\n",
        "        h_n, _ = hidden\n",
        "        h_n = torch.flatten(h_n, 1)  # Flatten the hidden state\n",
        "        # print(h_n[0])\n",
        "        x = self.fc(h_n)\n",
        "\n",
        "        # hidden = torch.flatten(hidden,1)\n",
        "        # print(hidden[0])\n",
        "        # x = self.fc(hidden)\n",
        "        return x, hidden\n",
        "\n",
        "model = LSTMRegressor(1,5,2,5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcFIdl-fB0GW",
        "outputId": "7804541f-ab8a-4f0e-ccfe-0e302e69252a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 5, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=320, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_size * self.bidirectional, out_size)\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.float()\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        h_n, _ = hidden\n",
        "        # h_n = torch.flatten(h_n, 1)\n",
        "        # print(h_n)\n",
        "        x = self.fc(h_n)\n",
        "        return x, hidden\n",
        "\n",
        "model = LSTMRegressor(1,5,2,5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibqd8eiGapul",
        "outputId": "3df52fe5-a268-40ef-daca-84b25470f7bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 5, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=5, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with torch.no_grad():\n",
        "#     for x, targets, x_len, target_len in test_loader:\n",
        "#         x = x.to(device).unsqueeze(2)\n",
        "#         targets = targets.to(device)\n",
        "#         hidden, state = model.init_hidden(x.shape[0])\n",
        "#         hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "#         # print(targets)\n",
        "\n",
        "# #         x = torch.transpose(x, 0, 1)\n",
        "# #         preds, _ = model(x, (hidden, state))\n",
        "# #         preds = torch.transpose(preds, 0, 1)\n",
        "\n",
        "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "#         # print(x_packed)\n",
        "#         preds_packed, _ = model(x_packed, (hidden, state))\n",
        "#         preds, _ = model(x_packed, (hidden, state))\n",
        "#         # preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
        "\n",
        "\n",
        "#         # print(preds)\n",
        "#         print(\"Preds shape before squeeze:\", preds.shape)\n",
        "#         preds = preds.squeeze(0)\n",
        "#         # preds = preds.view(-1, 5)  # Zamienia wymiary [1, 64, 5] na [64, 5]\n",
        "#         preds = preds[-1]\n",
        "#         mask_tgt = targets != pad\n",
        "#         # print(targets)\n",
        "#         # print(preds[0])\n",
        "#         print(\"Targets shape:\", targets.shape)\n",
        "#         print(\"Preds shape:\", preds.shape)\n",
        "#         print(\"Mask shape:\", mask_tgt.shape)\n",
        "#         print(torch.abs(preds[mask_tgt] - targets[mask_tgt]).mean())\n",
        "#         print()"
      ],
      "metadata": {
        "id": "rWBa07TACvuO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fun = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "bXV1bOsGv3Mm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_epochs = 101\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     for x, targets, x_len, target_len in train_loader:\n",
        "#         x = x.to(device).unsqueeze(2)\n",
        "#         targets = targets.to(device)\n",
        "#         hidden, state = model.init_hidden(x.size(0))\n",
        "#         hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "#         x = torch.transpose(x, 0, 1)\n",
        "#         preds, _ = model(x, (hidden, state))\n",
        "#         preds = torch.transpose(preds, 0, 1)\n",
        "\n",
        "#         preds = preds.squeeze(2)\n",
        "#         preds = preds.mean(dim=1)\n",
        "#         optimizer.zero_grad()\n",
        "#         mask = targets != pad\n",
        "#         loss = loss_fun(preds[mask], targets[mask])\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#     if epoch % 10 == 0:\n",
        "#         print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "-61lI-xWv9_W",
        "outputId": "b22e8214-aa4e-4370-8fa3-8ce9fb7e636b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 2.5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-c565b31fe274>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 new_grads.append(\n\u001b[0;32m--> 143\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 )\n\u001b[1;32m    145\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMRegressor(1,5,2,5).to(device)\n",
        "num_epochs = 101\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for x, targets, x_len, target_len in train_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "        x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "        preds, _ = model(x_packed, (hidden, state))\n",
        "        preds = torch.transpose(preds, 0, 1)\n",
        "\n",
        "        preds = preds.squeeze(2)\n",
        "        preds = preds.mean(dim=1)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh_qk-PV4Wk3",
        "outputId": "10d8f739-60ed-4aa3-eb4b-21eb0b806a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 2.22\n",
            "Epoch: 10, loss: 1.68\n",
            "Epoch: 20, loss: 2.24\n",
            "Epoch: 30, loss: 1.53\n",
            "Epoch: 40, loss: 1.38\n",
            "Epoch: 50, loss: 2.27\n",
            "Epoch: 60, loss: 2.1\n",
            "Epoch: 70, loss: 1.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_preds, num_preds = 0., 0.\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, targets, x_len, target_len in test_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.shape[0])\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "        x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "        preds_packed, _ = model(x_packed, (hidden, state))\n",
        "        preds, _ = model(x_packed, (hidden, state))\n",
        "        preds = torch.transpose(preds, 0, 1)\n",
        "\n",
        "        preds = preds.squeeze(2)\n",
        "        preds = preds.mean(dim=1)\n",
        "        preds = torch.argmax(preds, dim=1)\n",
        "        targets = torch.argmax(targets, dim=1)\n",
        "        true_preds += (preds == targets).sum().item()\n",
        "        num_preds += targets.shape[0]\n",
        "acc = true_preds / num_preds\n",
        "print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab5xtCcdtyyf",
        "outputId": "a5b2e3ef-a3de-4b42-be2e-ed4d84b93434"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 56.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_test = torch.tensor(data_test)"
      ],
      "metadata": {
        "id": "RKN9N9bYvLr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with torch.no_grad():\n",
        "#     hidden, state = model.init_hidden(len(data_test))\n",
        "#     hidden, state = hidden.to(device), state.to(device)\n",
        "#     preds,_ =  model(data_test.to(device).unsqueeze(2), (hidden,state))\n",
        "#     preds = torch.argmax(preds, dim=1)\n",
        "# print(f\"Accuracy: {(torch.argmax(preds,1).cpu()==targets_test).sum().item()/len(targets_test):.3}\")"
      ],
      "metadata": {
        "id": "1MIpqthKCzw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}