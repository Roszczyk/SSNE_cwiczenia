{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "aF7NhtuRuj3m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQk7qP3Wszsx",
        "outputId": "63389d0e-9255-49cc-aa84-c93e3e7da4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlL-F0T8ujBn",
        "outputId": "1994899d-3ea4-4a21-ec1e-51ca72c90683"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/train.pkl', 'rb') as f:\n",
        "    data_set = pickle.load(f)"
      ],
      "metadata": {
        "id": "HRKMm6B2uwFd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dz5vfxHvMmg",
        "outputId": "0bf5f3b8-0f00-4aa5-d6a4-2d362ae17003"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "targets = []\n",
        "for i in data_set:\n",
        "  data.append(i[0])\n",
        "  targets.append(i[1])"
      ],
      "metadata": {
        "id": "viCp1NWgEI53"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_array = np.array(targets)\n",
        "targets_array_reshaped = targets_array.reshape(-1, 1)\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "ohe.fit(targets_array_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "x-GkoyTUrksk",
        "outputId": "8e32bae0-4fc3-4fbb-c789-4bb8c83e5880"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneHotEncoder(handle_unknown='ignore', sparse_output=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets_ohe = ohe.transform(targets_array_reshaped)\n",
        "print(targets_ohe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52b_-RYisjYn",
        "outputId": "11edfd0f-1932-47bc-9cee-e2bbecc65e4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[-1])\n",
        "print(targets[-1])\n",
        "print(targets_ohe[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6eNqA5MIIcl",
        "outputId": "c96d1f2b-dbf3-46de-a564-335893d708dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[112. 112.   0.  64.   0. 112.  34. 144. 146. 112. 112. 179. 112. 112.\n",
            "  73.   3.  12. 112. 146.  60.  45. 112.  73.  88. 117.   8. 159. 145.\n",
            " 159. 112.  13.  80.  92. 159. 190. 112. 185. 190.   8.  73. 125.  77.\n",
            "  12.   0. 117. 190. 185. 112. 125. 125.  45.  41.  92.  28.  92.  12.\n",
            " 159.   0.  47.  12.  12.  88.  88.   0.  12. 112. 159.   8. 159.   0.\n",
            "  12. 112. 125.  23.  47.  41. 159. 112.  45.  12.   8. 145.  47.  33.\n",
            "  33.  33. 125.  73.   8.  13.  92.  88. 159. 120. 124. 185. 185.  77.\n",
            " 125.  88.  13. 120. 120. 112. 112. 112. 159. 172.  12. 117.  47.  88.\n",
            "  88.  36.  92.  33. 125.  88.  88.  88.  12. 112. 159.  88. 125. 119.\n",
            "  47.  88.  92. 159. 185. 112.  77.  33. 125.  65. 125.  33. 125.  88.\n",
            "  13. 120. 124. 112.  12.   0.   0.   0.  12. 112. 159. 145.   5.   0.\n",
            "  88. 112.  12.  47.  88.   0.  12. 112. 159. 145.   5.   0.  12. 112.\n",
            " 125. 125.  28. 159.  28.  38.  12. 117.  47. 114. 153.  88. 159.   8.\n",
            "   8. 112.  77.  38.  12.   0. 117. 190. 185. 112.  77.  33.  41. 145.\n",
            " 145. 106. 124. 112.  74.  41.  92.  88.  12. 112.  74.  41.  13. 117.\n",
            "  92.  80. 125. 185. 190. 114. 112. 112. 159.  88.  13.   8.  12. 117.\n",
            "  12. 125. 124. 106. 159. 112. 112. 112. 112. 112.  12.   0. 117. 190.\n",
            " 185. 112. 112. 112. 112. 112.]\n",
            "4\n",
            "[0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "labels = [label for _, label in data_set]\n",
        "\n",
        "class_counts = Counter(labels)\n",
        "classes = []\n",
        "print(\"Liczba klas:\", len(class_counts))\n",
        "for class_label, count in class_counts.items():\n",
        "    classes.append(count)\n",
        "classes = np.array(classes)\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "6xQID-J53J_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad5cf19-31cc-496e-9e8e-fd5bf92d5ffa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba klas: 5\n",
            "[1630  478  154  441  236]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target"
      ],
      "metadata": {
        "id": "JTnWdmaG49BT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = np.random.rand(len(data_set))>0.3"
      ],
      "metadata": {
        "id": "5JUCzIp8O5NX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices"
      ],
      "metadata": {
        "id": "Bai0Mly3O9Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7b0f7c-a850-4e93-ed69-16f2738f4ab2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ...,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = []\n",
        "targets_train = []\n",
        "data_test = []\n",
        "targets_test = []\n",
        "for i in range(len(data_set)):\n",
        "  if train_indices[i] == True:\n",
        "    data_train.append(data_set[i][0])\n",
        "    targets_train.append(targets_ohe[i])\n",
        "  else:\n",
        "    data_test.append(data_set[i][0])\n",
        "    targets_test.append(targets_ohe[i])"
      ],
      "metadata": {
        "id": "3gDvCohVPFh-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_size = len(data_set)\n",
        "\n",
        "# train_size = int(0.8 * dataset_size)\n",
        "# test_size = dataset_size - train_size\n",
        "\n",
        "\n",
        "# train_set = VariableLenDataset(data[:train_indices], targets[:train_indices])\n",
        "# test_set = VariableLenDataset(data[train_indices:], targets[train_indices:])"
      ],
      "metadata": {
        "id": "qGbQf80xGZbU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = VariableLenDataset(data_train, targets_train)\n",
        "test_set = VariableLenDataset(data_test, targets_test)"
      ],
      "metadata": {
        "id": "05cbXnJZMV_M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_set[2])"
      ],
      "metadata": {
        "id": "_gSWK_fJK6EO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a0b44e-1555-40bd-9b38-98171780d4a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 66., 100., 148., 148., 146.,  64., 146., 148.,  82.,   0.,  82.,\n",
            "       100.,  34., 132., 180.,  65.,  80.,  81., 131.,  52.,  34.,  52.,\n",
            "        64.,  52.,   3.,  66., 147.,  20.,   4., 132., 132., 100., 111.,\n",
            "        74., 110.,  60.,  92.,  65., 100., 189.,  44.,   8.,   5.,  76.,\n",
            "        31., 159.,   5., 124.,   4.,  12.,  51., 157.,  57.,  31., 183.,\n",
            "        57.,  65.,  92.,  69., 124., 122.,  79., 110.,  76.,  12.,  12.,\n",
            "        12.,  12.,   8., 159.,  12., 156., 100., 111.,  52., 121.,  36.,\n",
            "        47.,  41.,  41.,   8., 172.,  38.,  12.,  78.,  12.,  88.,  47.,\n",
            "       119.,  20.,  47.,  12., 159.,  20.,  20.,  76.,  60., 110., 132.,\n",
            "       185., 120.,  45., 110., 110.,  72., 124., 178.,  73.,   8.,  78.,\n",
            "        12.,  42., 173.,  12., 150.,  84.,  66., 152.,  69.,   8.,  41.,\n",
            "       159.,   5.,  78.,  44., 180.,  71.,  92., 152.,   6.,  12.,  45.,\n",
            "        92., 125.,   8., 156.,  12.,  12., 146.,   8., 185.,   0.,  88.,\n",
            "        92.,  90.,  12.,  12.,  12.,  78.,  92.,   3.,  45., 111., 111.,\n",
            "        71., 137.,  69.,  12.,  88.,  12.,  10.,   8., 172., 156., 152.,\n",
            "       100.,  12.,  12.,  77.,  52., 156., 148.,  12.,  12., 132.,   6.,\n",
            "         6., 185.,  47., 121.,  20.,  90.,  64., 111.,  92., 111.,  77.,\n",
            "        76.,  69., 100.,   8.,  76.,  76.,  69., 132.,   6.,   6.,   8.,\n",
            "        20.,  73.,  77., 111.,   6.,   8.,  13.,  12., 178.,   5.,  88.,\n",
            "       159., 121.,  58.,  44.,  47., 100., 156.,  12.,  41.,  88.,  73.,\n",
            "        20., 125.,  12., 124.,   5.,   0.,   5.,  47.,  12.,  12.,  12.,\n",
            "        12.,   8., 159., 185., 124., 100., 111.,  52., 121.,  36.,  47.,\n",
            "        41.,  41., 180.,   8.,  66.,   8., 146., 180.,  88.,  47., 119.,\n",
            "        20.,  73., 172., 158.,  20.,  20.,  20.,  78.,  69.,  12.,  12.,\n",
            "        47.,  47.,  47.,  30.,   8.,   6.,  45.,  12., 111., 111.,  38.,\n",
            "        12.,  12.,  12., 148.,   6.,   6., 185.,  47., 121.,  20.,  78.,\n",
            "        64., 111.,  77., 111.,  77.,  76., 141., 100.,   8.,  76.,  76.,\n",
            "         6., 132., 100., 111.,  74., 110.,  60., 159.,  79.,   5., 189.,\n",
            "       110.,  12.,   5.,  76.,  10.,  92.,   5., 124.,   4.,  12.,  51.,\n",
            "       157.,  57.,  31., 183.,  57.,  65.,  92.,  69., 124., 122.,  79.,\n",
            "       110.,  76.,  10.,  12.,  12.,  12.,   8., 159.,  12., 156., 100.,\n",
            "       111.,  52., 121.,  36.,  47.,  41.,  41.,   8., 172.,  38.,  12.,\n",
            "        78.,  12.,  88.,  47., 119.,  20.,  47.,  12.,  12.,  78.,  63.,\n",
            "        76.,  60., 110., 159., 132., 124.,  12.,  15., 110., 110.,  72.,\n",
            "       124., 178.,  73.,   8.,  78.,  12.,  12.,  30.,  12., 150.,  84.,\n",
            "        66., 152.,  69.,   8.,  41., 159.,   5.,  78.,  44., 180.,  71.,\n",
            "        92., 156., 132.,  79.,  45.,  92., 125.,   8., 156.,  12.,  12.,\n",
            "       146.,  12., 185.,   0.,  92., 108.,  90.,  47.,  12.,  12., 125.,\n",
            "        92.,   3.,  45., 111., 111.,  71., 137.,  69.,  12.,  47.,  12.,\n",
            "        10.,   8.,  41., 156., 152., 100.,  12.,  12.,  74.,  52., 156.,\n",
            "       148., 148.,  12.,  69.,   6.,   6., 185.,  47., 121.,  20.,  90.,\n",
            "        64., 111.,  92., 111.,  77.,  76., 141., 100.,   8.,  76.,  76.,\n",
            "        69., 132., 100.,   6.,   8.,  88.,  47., 141.,  77.,   6.,   8.,\n",
            "       152.,  12., 178.,   5.,  88., 159., 121.,  58.,  44.,  47., 100.,\n",
            "       156.,  12.,  41.,  88.,  73.,  20., 125.,  12., 124.,   5.,   0.,\n",
            "         5.,  47.,  12.,  12.,  12.,  12.,  12., 159., 185., 124.,   6.,\n",
            "       111.,  52., 121.,  36.,  47.,  41.,  41., 180.,   8.,  66.,   8.,\n",
            "       146., 180.,  88.,  47., 119.,  20.,  73.,  12., 158.,  20.,  20.,\n",
            "        20.,  78.,  69.,  12.,  12.,  47.,  47.,  47., 125.,   8.,   6.,\n",
            "        12.,  12., 111., 111.,  38.,  12.,  12.,  12.,  82.,   6.,   6.,\n",
            "       185.,  47., 121.,  88.,  90.,  64., 111.,  92., 111.,  77.,  76.,\n",
            "       141., 100.,   8.,  76.,  76.,  69., 132.,   6.,   6.,   8.,  47.,\n",
            "        47.,  10.,  10.,  82.,   8., 148.,  38.,  50.,  50.,  34.,  34.,\n",
            "        34.,  34.,  34.,  34., 144., 144., 144., 144.,  -1.]), array([1., 0., 0., 0., 0.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad = -100\n",
        "\n",
        "# def pad_collate(batch, pad_value=pad):\n",
        "#     xx, yy = zip(*batch)\n",
        "#     xx = [torch.tensor(x) for x in xx]\n",
        "#     x_lens = [len(x) for x in xx]\n",
        "#     yy_pad = torch.tensor(yy)\n",
        "#     y_lens = [1] * len(yy)\n",
        "#     # print(xx)\n",
        "#     # print(yy)\n",
        "\n",
        "#     xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "#     # yy_pad = pad_sequence(yy, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "#     return xx_pad, yy_pad, x_lens, y_lens\n",
        "\n",
        "def pad_collate(batch, pad_value=pad):\n",
        "    try:\n",
        "        xx, yy = zip(*batch)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error while unpacking batch: {e}\")\n",
        "        print(f\"Batch content: {batch}\")\n",
        "        raise\n",
        "\n",
        "    xx = [torch.tensor(x) for x in xx]\n",
        "    x_lens = [len(x) for x in xx]\n",
        "    yy_pad = torch.tensor(yy)\n",
        "    y_lens = [1] * len(yy)\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy_pad, x_lens, y_lens"
      ],
      "metadata": {
        "id": "gT4DVyAfws-7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=256\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "xBcnjNFqIn6H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_size = len(data)\n",
        "\n",
        "# train_size = int(0.8 * dataset_size)\n",
        "# test_size = dataset_size - train_size\n",
        "\n",
        "# train_set, test_set = random_split(data, [train_size, test_size])\n",
        "\n",
        "# batch_size=4\n",
        "# trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
        "# testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "nE3dVfPevMd-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set[0]\n"
      ],
      "metadata": {
        "id": "n4cE0wPFIndl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5ec8c5-4235-448f-fa9a-b2ddcfec9bb3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ -1.,  -1.,  -1., ...,  78.,  40., 144.]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_set[0][0]))\n",
        "print(len(train_set[1][0]))"
      ],
      "metadata": {
        "id": "8iAC0VKIw776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85a3ac4-c7cb-444c-dd0a-ade9cdef2c32"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4756\n",
            "5322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R2Ulv0AxYvE",
        "outputId": "182c7a2d-8fd0-42c8-d3f3-9901b9441c4d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-76b5b91029d1>:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  yy_pad = torch.tensor(yy)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  80.,  162.,   33.,  ...,  111.,  137.,   64.],\n",
              "         [  -1.,   -1.,  144.,  ..., -100., -100., -100.],\n",
              "         [  -1.,   -1.,   -1.,  ..., -100., -100., -100.],\n",
              "         [ 144.,    8.,  190.,  ..., -100., -100., -100.]], dtype=torch.float64),\n",
              " tensor([[0., 0., 0., 0., 1.],\n",
              "         [1., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0.]], dtype=torch.float64),\n",
              " [308, 288, 68, 270],\n",
              " [1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(320, out_size)\n",
        "        # self.fc = nn.Linear(hidden_size*90*self.bidirectional, out_size)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x = torch.transpose(x,0,1)\n",
        "        x = x.float()\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        # all_outputs = torch.transpose(all_outputs,0,1)\n",
        "        # out = torch.flatten(all_outputs,1)\n",
        "        # output, _ = pad_packed_sequence(all_outputs, batch_first=True)\n",
        "        # output = output[:, -1, :]\n",
        "\n",
        "        h_n, _ = hidden\n",
        "        h_n = torch.flatten(h_n, 1)  # Flatten the hidden state\n",
        "        # print(h_n[0])\n",
        "        x = self.fc(h_n)\n",
        "\n",
        "        # hidden = torch.flatten(hidden,1)\n",
        "        # print(hidden[0])\n",
        "        # x = self.fc(hidden)\n",
        "        return x, hidden\n",
        "\n",
        "model = LSTMRegressor(1,5,2,5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcFIdl-fB0GW",
        "outputId": "7804541f-ab8a-4f0e-ccfe-0e302e69252a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 5, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=320, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_size * self.bidirectional, out_size)\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.float()\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        h_n, _ = hidden\n",
        "        # h_n = torch.flatten(h_n, 1)\n",
        "        # print(h_n)\n",
        "        x = self.fc(h_n)\n",
        "        return x, hidden\n",
        "\n",
        "model = LSTMRegressor(1,5,2,5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibqd8eiGapul",
        "outputId": "3df52fe5-a268-40ef-daca-84b25470f7bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 5, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=5, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module): #Coś nie tak\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_size * self.bidirectional, 10)\n",
        "        self.fc2 = nn.Linear(10,out_size)\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.float()\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        h_n, _ = hidden\n",
        "        # h_n = torch.flatten(h_n, 1)\n",
        "        # print(h_n)\n",
        "        x = F.relu(self.fc(h_n[-1]))\n",
        "        x = F.tanh(self.fc2(x))\n",
        "        # x = F.softmax(x, dim=1)\n",
        "        return x, hidden\n",
        "\n",
        "model = LSTMRegressor(1,5,2,5).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR3Gw-nNEsaJ",
        "outputId": "018d6918-2281-46c2-846d-855b077b595f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMRegressor(\n",
              "  (lstm): LSTM(1, 5, num_layers=2, dropout=0.4)\n",
              "  (fc): Linear(in_features=5, out_features=10, bias=True)\n",
              "  (fc2): Linear(in_features=10, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lr=0.001 nie zbiega?\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fun = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "bXV1bOsGv3Mm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMRegressor(1,5,2,5).to(device)\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for x, targets, x_len, target_len in train_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        print(x)\n",
        "        preds, _ = model(x, (hidden, state))\n",
        "        # print(preds.size())\n",
        "        # preds = torch.transpose(preds, 0, 1)\n",
        "\n",
        "\n",
        "        # preds = preds.squeeze(2)\n",
        "        # preds = preds.mean(dim=1)\n",
        "        optimizer.zero_grad()\n",
        "        # mask = targets != pad\n",
        "        # print(preds.size())\n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-61lI-xWv9_W",
        "outputId": "404d9275-27bc-460d-903e-1a8ceb68e930"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-76b5b91029d1>:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  yy_pad = torch.tensor(yy)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[  -1.],\n",
            "         [   0.],\n",
            "         [  12.],\n",
            "         ...,\n",
            "         [  80.],\n",
            "         [  67.],\n",
            "         [   0.]],\n",
            "\n",
            "        [[  -1.],\n",
            "         [  92.],\n",
            "         [  12.],\n",
            "         ...,\n",
            "         [ 172.],\n",
            "         [  88.],\n",
            "         [  67.]],\n",
            "\n",
            "        [[  -1.],\n",
            "         [  13.],\n",
            "         [  78.],\n",
            "         ...,\n",
            "         [  13.],\n",
            "         [ 112.],\n",
            "         [  73.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]],\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]],\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]]], dtype=torch.float64)\n",
            "tensor([[[  -1.],\n",
            "         [   3.],\n",
            "         [  -1.],\n",
            "         ...,\n",
            "         [  67.],\n",
            "         [ 162.],\n",
            "         [  -1.]],\n",
            "\n",
            "        [[  -1.],\n",
            "         [ 159.],\n",
            "         [  -1.],\n",
            "         ...,\n",
            "         [  12.],\n",
            "         [  49.],\n",
            "         [  -1.]],\n",
            "\n",
            "        [[  -1.],\n",
            "         [   5.],\n",
            "         [  -1.],\n",
            "         ...,\n",
            "         [ 119.],\n",
            "         [  36.],\n",
            "         [  -1.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]],\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]],\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]]], dtype=torch.float64)\n",
            "tensor([[[ 145.],\n",
            "         [  32.],\n",
            "         [  60.],\n",
            "         ...,\n",
            "         [  -1.],\n",
            "         [  -1.],\n",
            "         [ 160.]],\n",
            "\n",
            "        [[   9.],\n",
            "         [  79.],\n",
            "         [  20.],\n",
            "         ...,\n",
            "         [  -1.],\n",
            "         [  -1.],\n",
            "         [  82.]],\n",
            "\n",
            "        [[   9.],\n",
            "         [  79.],\n",
            "         [  47.],\n",
            "         ...,\n",
            "         [  -1.],\n",
            "         [  -1.],\n",
            "         [  33.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]],\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]],\n",
            "\n",
            "        [[-100.],\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         ...,\n",
            "         [-100.],\n",
            "         [-100.],\n",
            "         [-100.]]], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e903efc14935>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print(preds.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMRegressor(1,5,2,5).to(device)\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for x, targets, x_len, target_len in train_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "        x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "        preds, _ = model(x_packed, (hidden, state))\n",
        "        # preds = torch.transpose(preds, 0, 1)\n",
        "\n",
        "        # preds = preds.squeeze(2)\n",
        "        # preds = preds.mean(dim=1)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
      ],
      "metadata": {
        "id": "kh_qk-PV4Wk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_preds, num_preds = 0., 0.\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, targets, x_len, target_len in test_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.shape[0])\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "        x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "        preds_packed, _ = model(x_packed, (hidden, state))\n",
        "        preds, _ = model(x_packed, (hidden, state))\n",
        "        # preds = torch.transpose(preds, 0, 1)\n",
        "\n",
        "        # preds = preds.squeeze(2)\n",
        "        # preds = preds.mean(dim=1)\n",
        "        preds = torch.argmax(preds, dim=1)\n",
        "        targets = torch.argmax(targets, dim=1)\n",
        "        print(preds)\n",
        "        print(targets)\n",
        "        true_preds += (preds == targets).sum().item()\n",
        "        num_preds += targets.shape[0]\n",
        "acc = true_preds / num_preds\n",
        "print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ],
      "metadata": {
        "id": "Ab5xtCcdtyyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6LQd7lyEmuw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
