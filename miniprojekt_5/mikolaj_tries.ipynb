{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import random_split, Dataset\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p5/train.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableLenDataset(Dataset):\n",
    "    def __init__(self, in_data, target):\n",
    "        self.data = [(x, y) for x, y in zip(in_data, target)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_data, target = self.data[idx]\n",
    "        return in_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attr = []\n",
    "data_targets = []\n",
    "for d in data:\n",
    "    data_attr.append(d[0])\n",
    "    data_targets.append(d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch, pad_value=-100):\n",
    "    try:\n",
    "        xx, yy = zip(*batch)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error while unpacking batch: {e}\")\n",
    "        print(f\"Batch content: {batch}\")\n",
    "        raise\n",
    "\n",
    "    xx = [torch.tensor(x) for x in xx]\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    yy_pad = torch.tensor(yy)\n",
    "    y_lens = [1] * len(yy)\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens\n",
    "    # return xx_pad, yy_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([144., 144., 144., 144.,  32., 146.,  33.,  78.,  92.,   5., 185.,\n",
      "       154.,  47.,  88.,  56., 113.,  37.,  60.,  33.,  38.,  47.,  12.,\n",
      "        12.,  47.,  60., 159.,  13.,  79., 149.,  32., 121., 185.,   8.,\n",
      "        47.,  92.,  65.,  92., 172.,  28.,  12.,  28., 172.,  47., 152.,\n",
      "       152., 145., 145., 145., 159.,  65.,  73.,  28.,  88.,  41., 125.,\n",
      "       119., 119.,  78.,  12.,  47.,  33.,  38.,  47., 145.,   5., 117.,\n",
      "        47., 159., 190., 124., 124.,  12.,  44.,  56.,  56.,  33.,  47.,\n",
      "       145., 145., 145., 159.,   5., 159.,  12., 125.,  47.,  28., 159.,\n",
      "       125., 125.,  60.,  33.,  47.,  92.,  47.,  38., 172.,  92., 117.,\n",
      "         8.,   8.,   0.,   0.,  67.,   0.,  65.,  65., 109.,  44.,  60.,\n",
      "        92., 145.,  28.,  47.,  74.,  73.,  44.,  79., 149.,  32., 124.,\n",
      "       185., 190., 114., 146.,  25., 132., 144., 185., 112., 112., 112.,\n",
      "        12.,  88.,  45., 120., 124.,  92., 159.,  12.,  92., 172.,  47.,\n",
      "        92.,  92., 145.,  88.,  41.,  40., 144.,  44.,  74.,  30., 149.,\n",
      "       127., 113., 127.,  33.,  41.,  80.,  80.,  92.,  92., 125.,  12.,\n",
      "        88.,  88.,  33.,  33.,  38.,  30., 144.,  30., 112., 159.,  12.,\n",
      "        12.,  92.,  47., 146., 168.,  30.,  30.,  40.,  44.,  33.,  92.,\n",
      "        88.,  88.,   0.,   8.,  77.,  60.,  79.,  60.,  92., 159.,  42.,\n",
      "        78.,  44.,  44.,  33.,  33.,  38.,  47., 145.,   8.,   5., 159.,\n",
      "        12.,  12.,  73.,  74.,  12., 159., 172.,  28.,  12.,  12.,   8.,\n",
      "        45.,  40.,  40.,  32., 148.,   8.,  12.,  47.,  56.,  47., 172.,\n",
      "        37., 127.,  66.,  33.,  78.,  92.,  41., 125., 159.,  47.,  38.,\n",
      "        78.,  88.,  92.,  80.,  88., 152.,  92., 145.,  66.,  66.,   8.,\n",
      "         5.,  60.,  60., 127.,  74., 168.,  40.,  44.,  33.,  33.,  33.,\n",
      "        56., 127.,  92., 145.,   5.,  13., 127.,  40.,  40.,  32.,  32.,\n",
      "        32.,  32.,  32.,  32.,  32.,  33.,  33.,  33.,  33.,  44.,  44.,\n",
      "       124., 112., 112., 112.,  73.,  88.,  92.,  23., 159., 109.,  44.,\n",
      "        33.,  77., 159.,  47.,  38.,  47., 152., 152.,  66.,  66.,  66.,\n",
      "       145., 145., 145., 159.,  92.,  92.,  60.,  33.,  33.,  92.,  78.,\n",
      "        44.,  44., 160., 172.,  80.,  92.,  74., 127.,  40.,  44.,  33.,\n",
      "        33., 132.,  73.,   5.,   8.,  12.,  88.,  33., 114., 125.,  60.,\n",
      "        92.,  41.,  78.,  60., 172.,  12.,  12.,  12.,  65.,  47.,  33.,\n",
      "        47.,  67.,  12., 112.,  38.,  33.,  88., 159.,  46., 172.,  77.,\n",
      "        77.,  28.,   8.,   5.,   0., 117.,   8., 185., 121.,  33.,  47.,\n",
      "        47.,  60., 127.,  78.,  30., 144.,  40.,  32.,  32.,  32.,  32.,\n",
      "        32.,  32., 144., 132.,  35., 112., 112.,  32.,   8., 132., 145.,\n",
      "       185., 112.,  12.,   0.,   0.,  98., 185., 124., 124., 109.,  44.,\n",
      "        78.,  60.,  41., 190., 159.,  88., 152., 152.,  66.,  66.,  66.,\n",
      "        66., 144.,   8., 148.,  12.,  73.,  78.,  65.,   0.,  47.,  33.,\n",
      "        40.,  40.,  32.,  33.,  92., 159., 172.,  12., 145., 159.,  12.,\n",
      "        92.,  68.,  47.,  60., 125.,  12., 190., 185.,   8., 145., 145.,\n",
      "       145., 145., 145.,   5.,  88.,  73.,  33.,  92., 154.,  41.,  88.,\n",
      "       127.,  74., 127.,  60.,  78.,  73.,  44.,  33.,  32.,  32., 132.,\n",
      "        73.,  60.,  38.,   8.,   8., 159.,   5.,   8., 159.,  92.,  80.,\n",
      "        47.,  33.,  60.,  20.,  78.,  44.,  44.,  33.,  33., 132.,  73.,\n",
      "         5.,   8.,  12.,  73., 125., 185.,  73.,  92., 172.,  12.,  47.,\n",
      "        92.,  92., 125., 112.,  73.,  73.,  44.,  32.,  33.,  56.,  56.,\n",
      "        33.,  33., 145.,  13.,  20.,  74.,  60.,  33., 180.,  12., 109.,\n",
      "        44.,  60.,  92.,   3., 117.,   8., 190.,  80.,  92.,   5., 159.,\n",
      "        12.,  88.,   8.,  74.,  40.,  44.,  33.,  92., 159.,  47., 127.,\n",
      "       113., 120.,  60., 113., 113., 113.,  37.,  32.,  32.,  32.,  33.,\n",
      "        33.,  33.,  33.,  44., 144.,  44.,  78., 125.,  12.,  12.,  38.,\n",
      "        47.,  77., 111.,  64., 152.,  66., 145.,  41.,  41., 145.,  47.,\n",
      "        47.,  47., 125.,  12.,  28.,  60.,  73.,  44., 121.,  33.,  40.,\n",
      "        30., 112., 190.,   8.,  12.,  47.,  38.,  12.,  12.,  35.,  71.,\n",
      "        41.,   8., 152.,  92.,  33.,  47., 152.,  92.,  80., 125., 146.,\n",
      "       121.,  44.,  44.,  33.,  60.,  77.,  47.,  41.,  13.,  47.,  88.,\n",
      "        12., 190.,  92., 106., 100., 124., 112., 112., 112., 185., 132.,\n",
      "        12.,  88., 125., 112.,  73.,  60., 125.,  88.,  13.,  77.,  12.,\n",
      "         0.,   0.,   0.,  12., 112., 121.,  33.,  47., 145.,  13.,  74.,\n",
      "        60.,  41., 172.,  60.,  13.,  47., 172.,  92.,  47.,   8.,   8.,\n",
      "         0.,   0.,   5., 159., 159., 159.,  12.,  12.,  12., 159., 146.,\n",
      "        74.,  12., 159., 172.,  12., 159.,   5.,  45.,  79.,  60.,  77.,\n",
      "       190., 190., 124., 124.,  12.,  92., 172.,  47., 156., 156., 144.,\n",
      "        44.,  33.,  33.,  47.,  47.,  60.,  92., 172.,  12., 145.,  13.,\n",
      "         8.,  77.,  41.,  41.,  74.,  60.,  38.,  47., 145.,   8.,  65.,\n",
      "        92.,  38.,  12.,   0.,  42., 190.,  45.,  92.,  92.,  26.,  44.,\n",
      "        33.,  47., 145., 190., 159.,  88., 152., 152.,  66., 145., 145.,\n",
      "       145., 145.,  47.,  33.,  33.,  77., 185.,  37., 168.,  40.,  44.,\n",
      "        37.,  79.,   5.,  92.,  92.,  92., 145.,  47.,  33., 127.,  60.,\n",
      "       127.,  40.,  44.,  33.,  33.,  32.,  33.,  33.,  33.,  33.,  47.,\n",
      "        12.,  41.,  41., 159.,  12., 117.,   8.,   8., 117.,  47.,  88.,\n",
      "        92., 121., 121.,  77.,  47.,  41.,  41., 106., 124.,  77., 125.,\n",
      "         9., 168.,  30.,  25., 144.,  33.,  33.,  33.,  38.,  47.,  12.,\n",
      "        13.,  88.,  12.,  77.,  56., 127.,  13., 145.,  41.,   8.,  12.,\n",
      "        71.,   8.,  12.,  12.,  12.,  47., 125.,  77.,  78.,  45., 159.,\n",
      "        92.,  33.,  92.,  12.,  77.,  78.,  30., 144.,  40.,  32.,  32.,\n",
      "        32.]), 4)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(73512)\n",
    "\n",
    "dataset_size = len(data)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_set, test_set = random_split(data, [train_size, test_size])\n",
    "\n",
    "print(train_set[6])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=pad_collate)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False, drop_last=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMRegressor(\n",
       "  (lstm): LSTM(1, 5, num_layers=2, dropout=0.4)\n",
       "  (fc): Linear(in_features=5, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = 2 if bidirectional else 1\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.4)\n",
    "        self.fc = nn.Linear(hidden_size*self.bidirectional, out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = torch.transpose(x,0,1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        all_outputs = torch.transpose(all_outputs,0,1)\n",
    "        # out = torch.flatten(all_outputs,1)\n",
    "        out = all_outputs[-1]\n",
    "        x = self.fc(out)\n",
    "        return x, hidden\n",
    "    \n",
    "model = LSTMRegressor(1,5,2,16).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_Seq_Regressor(\n",
       "  (lstm): LSTM(1, 200, proj_size=1)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM_Seq_Regressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.proj_size = out_size\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, proj_size = out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.proj_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # x = torch.transpose(x, 0, 1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        # all_outputs = torch.transpose(all_outputs, 0, 1)\n",
    "        return all_outputs, hidden\n",
    "    \n",
    "model = LSTM_Seq_Regressor(1, 200, 1, 1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = int(len(data) * 0.7)\n",
    "train_set = VariableLenDataset(data[:train_indices], targets[:train_indices])\n",
    "test_set = VariableLenDataset(data[train_indices:], targets[train_indices:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=50, shuffle=True, collate_fn=pad_collate)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=50, shuffle=False, drop_last=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001B459445F10>\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikol\\AppData\\Local\\Temp\\ipykernel_48468\\1506913400.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hidden = torch.tensor(hidden, dtype=torch.float32)\n",
      "C:\\Users\\mikol\\AppData\\Local\\Temp\\ipykernel_48468\\1506913400.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (2031) to match target batch_size (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[1;32m---> 21\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (2031) to match target batch_size (32)."
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for x, targets in train_loader:\n",
    "        print(\"done\")\n",
    "        x = x.to(device).unsqueeze(2).float()\n",
    "        # x = torch.tensor(x, dtype=torch.float32)\n",
    "#         x = x.unsqueeze(2)\n",
    "        targets = targets.to(device).long()\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        hidden = torch.tensor(hidden, dtype=torch.float32)\n",
    "        state = torch.tensor(state, dtype=torch.float32)\n",
    "        preds, _ = model(x, (hidden,state))\n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad() \n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikol\\AppData\\Local\\Temp\\ipykernel_48468\\3196653823.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  xx = [torch.tensor(x) for x in xx]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m101\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, targets, x_len, target_len \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      8\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      9\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 9\u001b[0m, in \u001b[0;36mpad_collate\u001b[1;34m(batch, pad_value)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m xx \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m x_lens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xx]\n\u001b[0;32m     11\u001b[0m yy_pad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(yy)\n",
      "Cell \u001b[1;32mIn[28], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m xx \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xx]\n\u001b[0;32m     10\u001b[0m x_lens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xx]\n\u001b[0;32m     11\u001b[0m yy_pad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(yy)\n",
      "\u001b[1;31mTypeError\u001b[0m: not a sequence"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "pad = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(101):\n",
    "    for x, targets, x_len, target_len in train_loader:\n",
    "        x = x.to(device).unsqueeze(2).float()\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        \n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        preds, _ = model(x, (hidden, state))\n",
    "        preds = torch.transpose(preds, 0, 1)\n",
    "        \n",
    "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
    "#         preds_packed, _ = model(x_packed, (hidden, state))\n",
    "#         preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
    "        \n",
    "        preds = preds.squeeze(2)\n",
    "        optimizer.zero_grad()\n",
    "        mask = targets != pad\n",
    "        loss = loss_fun(preds[mask], targets[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
