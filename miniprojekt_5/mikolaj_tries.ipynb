{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import random_split, Dataset\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p5/train.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableLenDataset(Dataset):\n",
    "    def __init__(self, in_data, target):\n",
    "        self.data = [(x, y) for x, y in zip(in_data, target)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_data, target = self.data[idx]\n",
    "        return in_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attr = []\n",
    "data_targets = []\n",
    "for d in data:\n",
    "    data_attr.append(d[0])\n",
    "    data_targets.append(d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "pad = 0\n",
    "\n",
    "def pad_collate(batch, pad_value=0):\n",
    "    xx, yy = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(73512)\n",
    "\n",
    "min_gen_val = 10\n",
    "max_gen_val = 1001\n",
    "samples = 1000\n",
    "max_gen_len = 32\n",
    "\n",
    "data = []\n",
    "targets = []\n",
    "max_val = -1\n",
    "for _ in range(samples):\n",
    "    seq_len = rng.integers(low=1, high=max_gen_len, size=1)\n",
    "    data_in = rng.integers(low=min_gen_val, high=max_gen_val, size=seq_len)\n",
    "    data_sum = np.array([data_in[:i + 1].sum() for i in range(len(data_in))])\n",
    "    data.append(torch.from_numpy(data_in))\n",
    "    targets.append(torch.from_numpy(data_sum))\n",
    "    max_val = data_sum[-1] if data_sum[-1] > max_val else max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = int(len(data) * 0.7)\n",
    "data = [(x / max_val).float() for x in data]\n",
    "targets = [(x / max_val).float() for x in targets]\n",
    "train_set = VariableLenDataset(data[:train_indices], targets[:train_indices])\n",
    "test_set = VariableLenDataset(data[train_indices:], targets[train_indices:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=50, shuffle=True, collate_fn=pad_collate)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=50, shuffle=False, drop_last=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_Seq_Regressor(\n",
       "  (lstm): LSTM(1, 200, proj_size=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTM_Seq_Regressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.proj_size = out_size\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, proj_size = out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.proj_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # x = torch.transpose(x, 0, 1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        # all_outputs = torch.transpose(all_outputs, 0, 1)\n",
    "        return all_outputs, hidden\n",
    "    \n",
    "model = LSTM_Seq_Regressor(1, 200, 1, 1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:878: UserWarning: LSTM with projections is not supported with oneDNN. Using default implementation. (Triggered internally at ..\\aten\\src\\ATen\\native\\RNN.cpp:1480.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 4.58e-06\n",
      "Epoch: 10, loss: 9.87e-10\n",
      "Epoch: 20, loss: 2.3e-10\n",
      "Epoch: 30, loss: 9.27e-11\n",
      "Epoch: 40, loss: 8.71e-11\n",
      "Epoch: 50, loss: 1.32e-10\n",
      "Epoch: 60, loss: 1.15e-10\n",
      "Epoch: 70, loss: 8.29e-11\n",
      "Epoch: 80, loss: 1.31e-10\n",
      "Epoch: 90, loss: 1.86e-10\n",
      "Epoch: 100, loss: 6.33e-08\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(101):\n",
    "    for x, targets, x_len, target_len in train_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        \n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        preds, _ = model(x, (hidden, state))\n",
    "        preds = torch.transpose(preds, 0, 1)\n",
    "        \n",
    "#         x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
    "#         preds_packed, _ = model(x_packed, (hidden, state))\n",
    "#         preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
    "        \n",
    "        preds = preds.squeeze(2)\n",
    "        optimizer.zero_grad()\n",
    "        mask = targets != pad\n",
    "        loss = loss_fun(preds[mask], targets[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0}\n",
      "tensor([[2.8939e-06, 5.4399e-06, 5.5305e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.5726e-06, 1.6340e-06, 1.9351e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.9906e-06, 2.4203e-06, 3.8234e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.1020e-06, 1.4586e-06, 1.6194e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.3329e-06, 3.4580e-06, 5.2528e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2716e-06, 2.7448e-06, 3.6860e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "tensor([[0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "{0}\n",
      "{0}\n",
      "tensor([[1.9380e-06, 4.1859e-06, 4.3642e-06,  ..., 4.2806e-05, 4.5153e-05,\n",
      "         0.0000e+00],\n",
      "        [2.6249e-06, 3.7650e-06, 6.3636e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.2014e-06, 3.5925e-06, 6.1853e-06,  ..., 5.4066e-05, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.5492e-07, 9.1785e-07, 2.8646e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.1897e-06, 3.9900e-06, 4.4431e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.4262e-07, 2.8588e-06, 5.6971e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "tensor([[0.0002, 0.0004, 0.0004,  ..., 0.0005, 0.0005, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0005, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "{0}\n",
      "{0}\n",
      "tensor([[7.6001e-08, 2.7214e-06, 2.9085e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.1575e-06, 1.6779e-06, 3.3294e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.0842e-06, 2.2245e-06, 2.3765e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [4.6770e-08, 2.0783e-06, 2.1689e-06,  ..., 4.6463e-05, 4.7547e-05,\n",
      "         0.0000e+00],\n",
      "        [2.0257e-06, 4.6127e-06, 5.4779e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [7.7462e-07, 2.1953e-06, 4.0865e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "tensor([[0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0005, 0.0005, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "{0}\n",
      "{0}\n",
      "tensor([[9.6462e-08, 2.2800e-06, 3.9871e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.4674e-06, 1.5492e-06, 3.5165e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.6428e-06, 4.0573e-06, 6.5361e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [2.5343e-06, 4.4022e-06, 4.5162e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.3209e-06, 5.0862e-06, 5.5539e-06,  ..., 3.9175e-05, 4.1242e-05,\n",
      "         4.1371e-05],\n",
      "        [2.1163e-06, 3.7796e-06, 4.1713e-06,  ..., 4.1505e-05, 4.4037e-05,\n",
      "         0.0000e+00]])\n",
      "tensor([[0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0005, 0.0005, 0.0005],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0005, 0.0005, 0.0000]])\n",
      "{0}\n",
      "{0}\n",
      "tensor([[1.1546e-06, 1.9497e-06, 3.8936e-06,  ..., 4.5299e-05, 4.7050e-05,\n",
      "         4.9389e-05],\n",
      "        [1.9877e-06, 3.3908e-06, 5.9953e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.0403e-06, 4.9225e-06, 6.9365e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.2803e-06, 1.6399e-06, 2.6483e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.3560e-06, 2.8179e-06, 3.2651e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.9760e-06, 4.3437e-06, 4.9108e-06,  ..., 3.6132e-05, 3.8670e-05,\n",
      "         0.0000e+00]])\n",
      "tensor([[0.0002, 0.0004, 0.0004,  ..., 0.0005, 0.0005, 0.0005],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0005, 0.0005, 0.0000]])\n",
      "{0}\n",
      "{0}\n",
      "tensor([[1.3739e-06, 1.4177e-06, 2.5928e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.0579e-06, 4.1917e-06, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.9231e-07, 5.2616e-07, 3.2359e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.7217e-06, 2.6746e-06, 2.8705e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.8354e-06, 4.4577e-06, 6.1765e-06,  ..., 4.0131e-05, 4.0807e-05,\n",
      "         4.3317e-05],\n",
      "        [2.7594e-06, 5.1037e-06, 5.7293e-06,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n",
      "tensor([[0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0005, 0.0005, 0.0005],\n",
      "        [0.0002, 0.0004, 0.0004,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "{0}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for x, targets, x_len, target_len in test_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        int_targets = []\n",
    "        for target_1 in targets:\n",
    "                for target_2 in target_1:\n",
    "                    int_targets.append(int(target_2))\n",
    "        print(set(list(int_targets)))\n",
    "        hidden, state = model.init_hidden(x.shape[0])\n",
    "        hidden, state = hidden.to(device), state.to(device)\n",
    "\n",
    "#         x = torch.transpose(x, 0, 1)        \n",
    "#         preds, _ = model(x, (hidden, state))\n",
    "#         preds = torch.transpose(preds, 0, 1)\n",
    "        \n",
    "        x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
    "        preds_packed, _ = model(x_packed, (hidden, state))\n",
    "        preds, pred_len = pad_packed_sequence(preds_packed, batch_first=True, padding_value=pad)\n",
    "        \n",
    "        preds = preds.squeeze(2)\n",
    "        mask_tgt = targets != pad\n",
    "        print(targets)\n",
    "        print(preds)\n",
    "        int_targets = []\n",
    "        int_preds = []\n",
    "        for i in range(len(targets)):\n",
    "            for j in range(len(targets[i])):\n",
    "                int_targets.append(int(round(float(targets[i][j]))))\n",
    "                int_preds.append(int(preds[i][j]))\n",
    "        print(set(int_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
