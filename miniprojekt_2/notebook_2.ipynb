{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "import torch.utils.data as data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Size(sqf)</th>\n",
       "      <th>Floor</th>\n",
       "      <th>HallwayType</th>\n",
       "      <th>HeatingType</th>\n",
       "      <th>AptManageType</th>\n",
       "      <th>N_Parkinglot(Ground)</th>\n",
       "      <th>N_Parkinglot(Basement)</th>\n",
       "      <th>TimeToBusStop</th>\n",
       "      <th>TimeToSubway</th>\n",
       "      <th>N_manager</th>\n",
       "      <th>N_elevators</th>\n",
       "      <th>SubwayStation</th>\n",
       "      <th>N_FacilitiesInApt</th>\n",
       "      <th>N_FacilitiesNearBy(Total)</th>\n",
       "      <th>N_SchoolNearBy(Total)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141592</td>\n",
       "      <td>2006</td>\n",
       "      <td>814</td>\n",
       "      <td>3</td>\n",
       "      <td>terraced</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>management_in_trust</td>\n",
       "      <td>111.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>5min~10min</td>\n",
       "      <td>10min~15min</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kyungbuk_uni_hospital</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51327</td>\n",
       "      <td>1985</td>\n",
       "      <td>587</td>\n",
       "      <td>8</td>\n",
       "      <td>corridor</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>self_management</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0~5min</td>\n",
       "      <td>5min~10min</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Daegu</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48672</td>\n",
       "      <td>1985</td>\n",
       "      <td>587</td>\n",
       "      <td>6</td>\n",
       "      <td>corridor</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>self_management</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0~5min</td>\n",
       "      <td>5min~10min</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Daegu</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380530</td>\n",
       "      <td>2006</td>\n",
       "      <td>2056</td>\n",
       "      <td>8</td>\n",
       "      <td>terraced</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>management_in_trust</td>\n",
       "      <td>249.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>0~5min</td>\n",
       "      <td>0-5min</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Sin-nam</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78318</td>\n",
       "      <td>1992</td>\n",
       "      <td>644</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>self_management</td>\n",
       "      <td>142.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5min~10min</td>\n",
       "      <td>15min~20min</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Myung-duk</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>570796</td>\n",
       "      <td>2007</td>\n",
       "      <td>1928</td>\n",
       "      <td>24</td>\n",
       "      <td>terraced</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>management_in_trust</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0~5min</td>\n",
       "      <td>0-5min</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Kyungbuk_uni_hospital</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>307079</td>\n",
       "      <td>2015</td>\n",
       "      <td>644</td>\n",
       "      <td>22</td>\n",
       "      <td>terraced</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>management_in_trust</td>\n",
       "      <td>102.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0~5min</td>\n",
       "      <td>5min~10min</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Daegu</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>357522</td>\n",
       "      <td>2007</td>\n",
       "      <td>868</td>\n",
       "      <td>20</td>\n",
       "      <td>terraced</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>management_in_trust</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0~5min</td>\n",
       "      <td>0-5min</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Kyungbuk_uni_hospital</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>312389</td>\n",
       "      <td>1978</td>\n",
       "      <td>1327</td>\n",
       "      <td>1</td>\n",
       "      <td>corridor</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>self_management</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0~5min</td>\n",
       "      <td>0-5min</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Kyungbuk_uni_hospital</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>393805</td>\n",
       "      <td>2007</td>\n",
       "      <td>868</td>\n",
       "      <td>13</td>\n",
       "      <td>terraced</td>\n",
       "      <td>individual_heating</td>\n",
       "      <td>management_in_trust</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0~5min</td>\n",
       "      <td>0-5min</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Kyungbuk_uni_hospital</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4124 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice  YearBuilt  Size(sqf)  Floor HallwayType         HeatingType  \\\n",
       "0        141592       2006        814      3    terraced  individual_heating   \n",
       "1         51327       1985        587      8    corridor  individual_heating   \n",
       "2         48672       1985        587      6    corridor  individual_heating   \n",
       "3        380530       2006       2056      8    terraced  individual_heating   \n",
       "4         78318       1992        644      2       mixed  individual_heating   \n",
       "...         ...        ...        ...    ...         ...                 ...   \n",
       "4119     570796       2007       1928     24    terraced  individual_heating   \n",
       "4120     307079       2015        644     22    terraced  individual_heating   \n",
       "4121     357522       2007        868     20    terraced  individual_heating   \n",
       "4122     312389       1978       1327      1    corridor  individual_heating   \n",
       "4123     393805       2007        868     13    terraced  individual_heating   \n",
       "\n",
       "            AptManageType  N_Parkinglot(Ground)  N_Parkinglot(Basement)  \\\n",
       "0     management_in_trust                 111.0                   184.0   \n",
       "1         self_management                  80.0                    76.0   \n",
       "2         self_management                  80.0                    76.0   \n",
       "3     management_in_trust                 249.0                   536.0   \n",
       "4         self_management                 142.0                    79.0   \n",
       "...                   ...                   ...                     ...   \n",
       "4119  management_in_trust                   0.0                  1270.0   \n",
       "4120  management_in_trust                 102.0                   400.0   \n",
       "4121  management_in_trust                   0.0                  1270.0   \n",
       "4122      self_management                  87.0                     0.0   \n",
       "4123  management_in_trust                   0.0                  1270.0   \n",
       "\n",
       "     TimeToBusStop TimeToSubway  N_manager  N_elevators  \\\n",
       "0       5min~10min  10min~15min        3.0          0.0   \n",
       "1           0~5min   5min~10min        2.0          2.0   \n",
       "2           0~5min   5min~10min        2.0          2.0   \n",
       "3           0~5min       0-5min        5.0         11.0   \n",
       "4       5min~10min  15min~20min        4.0          8.0   \n",
       "...            ...          ...        ...          ...   \n",
       "4119        0~5min       0-5min       14.0         16.0   \n",
       "4120        0~5min   5min~10min        5.0         10.0   \n",
       "4121        0~5min       0-5min       14.0         16.0   \n",
       "4122        0~5min       0-5min        1.0          4.0   \n",
       "4123        0~5min       0-5min       14.0         16.0   \n",
       "\n",
       "              SubwayStation  N_FacilitiesInApt  N_FacilitiesNearBy(Total)  \\\n",
       "0     Kyungbuk_uni_hospital                  5                        6.0   \n",
       "1                     Daegu                  3                       12.0   \n",
       "2                     Daegu                  3                       12.0   \n",
       "3                   Sin-nam                  5                        3.0   \n",
       "4                 Myung-duk                  3                        9.0   \n",
       "...                     ...                ...                        ...   \n",
       "4119  Kyungbuk_uni_hospital                 10                        9.0   \n",
       "4120                  Daegu                  7                        7.0   \n",
       "4121  Kyungbuk_uni_hospital                 10                        9.0   \n",
       "4122  Kyungbuk_uni_hospital                  3                        7.0   \n",
       "4123  Kyungbuk_uni_hospital                 10                        9.0   \n",
       "\n",
       "      N_SchoolNearBy(Total)  \n",
       "0                       9.0  \n",
       "1                       4.0  \n",
       "2                       4.0  \n",
       "3                       7.0  \n",
       "4                      14.0  \n",
       "...                     ...  \n",
       "4119                   10.0  \n",
       "4120                   11.0  \n",
       "4121                   10.0  \n",
       "4122                   11.0  \n",
       "4123                   10.0  \n",
       "\n",
       "[4124 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5min~10min' '0~5min' '10min~15min']\n",
      "['10min~15min' '5min~10min' '0-5min' '15min~20min' 'no_bus_stop_nearby']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = [\"HallwayType\", \"SubwayStation\"]\n",
    "\n",
    "print(df[\"TimeToBusStop\"].unique())\n",
    "print(df[\"TimeToSubway\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 2.0 0.0]\n",
      "[2.0 3.0 4.0 1.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "dataType = \"TimeToBusStop\"\n",
    "df.loc[df[dataType] == '0~5min', dataType] = np.float64(2.0)\n",
    "df.loc[df[dataType] == '5min~10min', dataType] = np.float64(1.0)\n",
    "df.loc[df[dataType] == '10min~15min', dataType] = np.float64(0.0)\n",
    "print(df[dataType].unique())\n",
    "\n",
    "dataType = \"TimeToSubway\"\n",
    "df.loc[df[dataType] == 'no_bus_stop_nearby', dataType] = np.float64(0.0)\n",
    "df.loc[df[dataType] == '0-5min', dataType] = np.float64(4.0)\n",
    "df.loc[df[dataType] == '5min~10min', dataType] = np.float64(3.0)\n",
    "df.loc[df[dataType] == '10min~15min', dataType] = np.float64(2.0)\n",
    "df.loc[df[dataType] == '15min~20min', dataType] = np.float64(1.0)\n",
    "print(df[dataType].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.HeatingType = (df.HeatingType==df[\"HeatingType\"].unique()[0]).astype(int)\n",
    "df.AptManageType = (df.AptManageType==df[\"AptManageType\"].unique()[0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bangoge</th>\n",
       "      <th>Banwoldang</th>\n",
       "      <th>Chil-sung-market</th>\n",
       "      <th>Daegu</th>\n",
       "      <th>Kyungbuk_uni_hospital</th>\n",
       "      <th>Myung-duk</th>\n",
       "      <th>Sin-nam</th>\n",
       "      <th>no_subway_nearby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bangoge  Banwoldang  Chil-sung-market  Daegu  Kyungbuk_uni_hospital  \\\n",
       "0        0           0                 0      0                      1   \n",
       "1        0           0                 0      1                      0   \n",
       "2        0           0                 0      1                      0   \n",
       "3        0           0                 0      0                      0   \n",
       "4        0           0                 0      0                      0   \n",
       "\n",
       "   Myung-duk  Sin-nam  no_subway_nearby  \n",
       "0          0        0                 0  \n",
       "1          0        0                 0  \n",
       "2          0        0                 0  \n",
       "3          0        1                 0  \n",
       "4          1        0                 0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_values0 = pd.get_dummies(df[categorical_columns[0]])\n",
    "categorical_values0.head()\n",
    "categorical_values1 = pd.get_dummies(df[categorical_columns[1]])\n",
    "categorical_values1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=categorical_columns,inplace=True)\n",
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.rand(len(df))>0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Size(sqf)</th>\n",
       "      <th>Floor</th>\n",
       "      <th>HeatingType</th>\n",
       "      <th>AptManageType</th>\n",
       "      <th>N_Parkinglot(Ground)</th>\n",
       "      <th>N_Parkinglot(Basement)</th>\n",
       "      <th>TimeToBusStop</th>\n",
       "      <th>TimeToSubway</th>\n",
       "      <th>N_manager</th>\n",
       "      <th>N_elevators</th>\n",
       "      <th>N_FacilitiesInApt</th>\n",
       "      <th>N_FacilitiesNearBy(Total)</th>\n",
       "      <th>N_SchoolNearBy(Total)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141592.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51327.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48672.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380530.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78318.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>570796.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>307079.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>357522.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>312389.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>393805.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4124 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice  YearBuilt  Size(sqf)  Floor  HeatingType  AptManageType  \\\n",
       "0      141592.0     2006.0      814.0    3.0          1.0            1.0   \n",
       "1       51327.0     1985.0      587.0    8.0          1.0            0.0   \n",
       "2       48672.0     1985.0      587.0    6.0          1.0            0.0   \n",
       "3      380530.0     2006.0     2056.0    8.0          1.0            1.0   \n",
       "4       78318.0     1992.0      644.0    2.0          1.0            0.0   \n",
       "...         ...        ...        ...    ...          ...            ...   \n",
       "4119   570796.0     2007.0     1928.0   24.0          1.0            1.0   \n",
       "4120   307079.0     2015.0      644.0   22.0          1.0            1.0   \n",
       "4121   357522.0     2007.0      868.0   20.0          1.0            1.0   \n",
       "4122   312389.0     1978.0     1327.0    1.0          1.0            0.0   \n",
       "4123   393805.0     2007.0      868.0   13.0          1.0            1.0   \n",
       "\n",
       "      N_Parkinglot(Ground)  N_Parkinglot(Basement)  TimeToBusStop  \\\n",
       "0                    111.0                   184.0            1.0   \n",
       "1                     80.0                    76.0            2.0   \n",
       "2                     80.0                    76.0            2.0   \n",
       "3                    249.0                   536.0            2.0   \n",
       "4                    142.0                    79.0            1.0   \n",
       "...                    ...                     ...            ...   \n",
       "4119                   0.0                  1270.0            2.0   \n",
       "4120                 102.0                   400.0            2.0   \n",
       "4121                   0.0                  1270.0            2.0   \n",
       "4122                  87.0                     0.0            2.0   \n",
       "4123                   0.0                  1270.0            2.0   \n",
       "\n",
       "      TimeToSubway  N_manager  N_elevators  N_FacilitiesInApt  \\\n",
       "0              2.0        3.0          0.0                5.0   \n",
       "1              3.0        2.0          2.0                3.0   \n",
       "2              3.0        2.0          2.0                3.0   \n",
       "3              4.0        5.0         11.0                5.0   \n",
       "4              1.0        4.0          8.0                3.0   \n",
       "...            ...        ...          ...                ...   \n",
       "4119           4.0       14.0         16.0               10.0   \n",
       "4120           3.0        5.0         10.0                7.0   \n",
       "4121           4.0       14.0         16.0               10.0   \n",
       "4122           4.0        1.0          4.0                3.0   \n",
       "4123           4.0       14.0         16.0               10.0   \n",
       "\n",
       "      N_FacilitiesNearBy(Total)  N_SchoolNearBy(Total)  \n",
       "0                           6.0                    9.0  \n",
       "1                          12.0                    4.0  \n",
       "2                          12.0                    4.0  \n",
       "3                           3.0                    7.0  \n",
       "4                           9.0                   14.0  \n",
       "...                         ...                    ...  \n",
       "4119                        9.0                   10.0  \n",
       "4120                        7.0                   11.0  \n",
       "4121                        9.0                   10.0  \n",
       "4122                        7.0                   11.0  \n",
       "4123                        9.0                   10.0  \n",
       "\n",
       "[4124 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2006.,  814.,    3.,  ...,    5.,    6.,    9.],\n",
      "        [1985.,  587.,    6.,  ...,    3.,   12.,    4.],\n",
      "        [2006., 2056.,    8.,  ...,    5.,    3.,    7.],\n",
      "        ...,\n",
      "        [2007., 1928.,   24.,  ...,   10.,    9.,   10.],\n",
      "        [2015.,  644.,   22.,  ...,    7.,    7.,   11.],\n",
      "        [2007.,  868.,   13.,  ...,   10.,    9.,   10.]])\n"
     ]
    }
   ],
   "source": [
    "numerical_data = torch.from_numpy(df.values[train_indices,1:]).float()\n",
    "print(numerical_data)\n",
    "categorical_data0 = torch.from_numpy(categorical_values0.values[train_indices]).float()\n",
    "categorical_data1 = torch.from_numpy(categorical_values1.values[train_indices]).float()\n",
    "targets = torch.from_numpy(df.values[train_indices,0]).float()\n",
    "\n",
    "test_numerical_data = torch.from_numpy(df.values[~train_indices,1:]).float()\n",
    "test_categorical_data0 = torch.from_numpy(categorical_values0.values[~train_indices]).float()\n",
    "test_categorical_data1 = torch.from_numpy(categorical_values1.values[~train_indices]).float()\n",
    "test_targets = torch.from_numpy(df.values[~train_indices,0]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1290, 14])\n",
      "torch.Size([2834, 14])\n"
     ]
    }
   ],
   "source": [
    "# # Policzenie liczby wejść do sieci\n",
    "# inputs_num = len(df[1:].columns)\n",
    "# print(inputs_num)\n",
    "\n",
    "print(test_numerical_data.shape)\n",
    "print(numerical_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2834, 14])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2834, 14)\n"
     ]
    }
   ],
   "source": [
    "print(numerical_data.shape)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_data = scaler.fit_transform(numerical_data)\n",
    "test_numerical_data = scaler.transform(test_numerical_data)\n",
    "print(numerical_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(torch.from_numpy(numerical_data).float(),categorical_data0, categorical_data1,targets)\n",
    "test_dataset = data.TensorDataset(torch.from_numpy(test_numerical_data).float(),test_categorical_data0,test_categorical_data1,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "num_inputs = df.shape[1] + len(categorical_columns) - 1\n",
    "print(num_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffordabilityEstim(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(AffordabilityEstim, self).__init__()\n",
    "        self.lin1 =nn.Linear(num_inputs, 120) \n",
    "        self.bn1 = nn.BatchNorm1d(120)\n",
    "        self.act1 =nn.ReLU()\n",
    "        self.lin2 =nn.Linear(120, 240)\n",
    "        self.bn2 = nn.BatchNorm1d(240)\n",
    "        self.act2 =nn.ReLU()\n",
    "        self.lin3 =nn.Linear(240, num_outputs)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin3(x)\n",
    "        # x = 1000000 * x\n",
    "        # x = abs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x):\n",
    "    # CHEAP\n",
    "    if x <= 100000:\n",
    "        return 0\n",
    "    # AVERAGE\n",
    "    if x > 100000 and x <= 350000:\n",
    "        return 1\n",
    "    # EXPENSIVE \n",
    "    if x > 350000:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    # ZMIENIĆ TO NA REGRESJĘ\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval() #*********#\n",
    "    for numerical_data,categorical_data0, categorical_data1,labels in data_loader:\n",
    "        inputs = torch.cat([numerical_data,categorical_data0, categorical_data1],dim=1)\n",
    "        pred = model(inputs)\n",
    "        for i in range(len(pred)):\n",
    "            print(classify(pred[i]), classify(labels[i]))\n",
    "            if classify(pred[i]) == classify(labels[i]):\n",
    "                correct = correct + 1\n",
    "                total = total + 1\n",
    "            else:\n",
    "                total = total + 1\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AffordabilityEstim(numerical_data.shape[1]+categorical_data0.shape[1]+categorical_data1.shape[1], 1)\n",
    "\n",
    "epochs = 1000\n",
    "opt = optim.Adam(model.parameters(), lr=10)\n",
    "loss_module = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for numerical_data,categorical_data0, categorical_data1,labels in train_loader:\n",
    "\n",
    "        # inputs, labels = batch\n",
    "        inputs = torch.cat([numerical_data, categorical_data0, categorical_data1],dim=1)\n",
    "        preds = model(inputs)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "        loss = loss_module(preds, labels)\n",
    "\n",
    "        # training steps for normal model\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true,y_pred):\n",
    "    return np.absolute(np.subtract(y_true, y_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 89200.0781, 114471.7812, 116199.3750, 230585.4375, 101980.6562,\n",
      "        230585.4375, 230585.4375,  88728.9062, 333542.4375,  61334.0547,\n",
      "        101509.5000, 176002.1562, 115257.0469, 125279.5469, 326540.2188,\n",
      "        301451.7812, 331165.1875, 310880.7188, 174745.7188,  59920.5664,\n",
      "        126378.9219, 102922.9531, 236224.0000, 301328.1875, 177101.5156,\n",
      "        275215.1875, 125750.7031, 230585.4375, 157460.8281, 105760.9375,\n",
      "         74695.3906, 270086.4688, 126693.0312, 230585.4375, 152736.6875,\n",
      "        242837.2188, 343031.2500, 217306.4688, 193410.1250, 179461.0625,\n",
      "         89357.1250, 297312.2812, 323020.1562, 349178.2812, 342241.5000,\n",
      "         66986.6641, 230585.4375, 168604.8750, 177886.7812, 230585.4375,\n",
      "        362974.5625, 330024.7188, 324754.3438, 313482.0312, 328222.7500,\n",
      "        295382.0938, 321285.9375,  67614.8750, 254478.6875, 276082.2812,\n",
      "        126064.8125, 252550.2500, 123866.0781, 201498.7188])\n",
      "tensor([ 61334.0547, 230585.4375, 106232.0938,  57906.6641,  57278.4453,\n",
      "        230585.4375, 167034.3281, 178200.8906, 290179.4688, 280837.3750,\n",
      "        344814.7500, 248641.4531, 256018.6406, 176787.4062, 230585.4375,\n",
      "        239635.7812, 304862.6562, 316950.4375, 311747.8438, 310880.7188,\n",
      "        103080.0156, 115030.9531, 101666.5312, 310013.6250, 126693.0312,\n",
      "        230585.4375,  60862.8984, 124651.3438, 175688.0312, 105638.8906,\n",
      "        101509.5000, 236167.3906, 102922.9531, 152422.5938, 103237.0938,\n",
      "        242145.0312, 249503.5938, 230585.4375, 249503.5938, 244301.0000,\n",
      "        252972.0000, 246902.2969, 252104.8906, 255573.3281, 256440.4375,\n",
      "        253839.1094, 263382.1875, 177415.6250, 392165.7188, 144936.0312,\n",
      "        249271.1094, 240410.8281, 106581.2031, 327423.3750, 125279.5469,\n",
      "        201184.6094, 367886.9062, 200399.3594, 200870.5156, 200399.3594,\n",
      "        253839.1094,  59606.4688, 238825.2969, 156361.4531])\n",
      "tensor([248636.5000, 114245.7031, 168290.7656, 230585.4375, 175688.0312,\n",
      "        201498.7188, 230585.4375, 362107.4375, 211022.2500, 211022.2500,\n",
      "        230585.4375, 210865.2031, 211493.4219, 222921.2188, 124180.1719,\n",
      "        123866.0781, 230585.4375,  61334.0547, 103394.1094, 246902.2969,\n",
      "        240502.8906, 217463.5156, 218248.7969, 212408.8906, 230585.4375,\n",
      "        199771.1406, 102608.8594, 322334.9375, 230585.4375, 153364.9062,\n",
      "        178687.3438, 230585.4375, 209922.8750, 210236.9844, 209765.8281,\n",
      "        230585.4375, 237034.5000, 327407.2812, 209294.6719, 208980.5625,\n",
      "        210551.0938, 209922.8750, 230585.4375, 209608.7812, 209765.8281,\n",
      "        209451.7188, 230585.4375, 230585.4375, 230585.4375, 230585.4375,\n",
      "        208980.5625, 230585.4375, 230585.4375, 209137.6250, 208980.5625,\n",
      "        230585.4375, 230585.4375, 230585.4375, 208980.5625, 171440.2031,\n",
      "         74381.2969, 230585.4375, 175373.9375, 230585.4375])\n",
      "tensor([175059.8281, 176630.3438, 230585.4375, 152893.7344, 208980.5625,\n",
      "        209608.7812, 209294.6719, 208666.4688, 179618.1094, 250816.0312,\n",
      "        125907.7656, 125436.6094, 200085.2344, 123551.9844, 201027.5625,\n",
      "        230585.4375, 325803.3750, 231888.5000, 230585.4375, 259681.2812,\n",
      "        230585.4375, 103394.1094, 230585.4375, 298792.9688, 210394.0469,\n",
      "        210079.9375, 291242.5625, 299913.5938,  60548.7812, 124965.4375,\n",
      "        176944.4688, 200242.2969,  61019.9258, 239692.4062, 233622.7031,\n",
      "        300780.6875, 230585.4375, 167236.0469,  59920.5664, 126064.8125,\n",
      "        230585.4375, 224334.6875, 357849.2812, 166877.2812, 249227.2969,\n",
      "        102922.9531, 102922.9531, 175216.8750,  60862.8984, 168447.8125,\n",
      "        362974.5625, 230585.4375,  88861.5938, 106110.0469,  61019.9258,\n",
      "        125122.5000, 230585.4375, 174902.7812, 175530.9844, 116984.6094,\n",
      "        334360.2188, 227918.5000, 156832.6250, 157303.7969])\n",
      "tensor([304920.1875, 175373.9375, 124494.2812, 228075.5469, 206446.5625,\n",
      "        352646.6562, 249276.0781, 116984.6094, 230585.4375, 355170.6562,\n",
      "        329956.9688, 134611.6250, 134140.4688, 134454.5781, 134140.4688,\n",
      "        136653.3125, 134768.6875, 135711.0000, 136339.2188, 135396.8906,\n",
      "        134925.7344, 230585.4375, 134768.6875, 134140.4688, 135082.7812,\n",
      "        135868.0469, 136653.3125, 136182.1562, 134611.6250, 136025.1094,\n",
      "        136182.1562, 135711.0000, 169076.0312, 136339.2188, 133826.3750,\n",
      "        133826.3750, 136182.1562, 136496.2656, 136496.2656, 218248.7969,\n",
      "        293647.8750, 199771.1406, 133826.3750,  60548.7812, 133983.4062,\n",
      "        230585.4375, 172619.9375, 230585.4375, 223235.3125, 222450.0469,\n",
      "        230585.4375, 103237.0938, 230585.4375, 218091.7344, 171283.1406,\n",
      "        230585.4375, 103080.0156, 167662.5312, 201655.7656, 114785.8750,\n",
      "        230585.4375, 200870.5156, 258174.6094, 228546.7031])\n",
      "tensor([322204.7188, 207231.8438, 167505.5000, 210708.1406, 210079.9375,\n",
      "        206348.9062, 230585.4375, 248360.2031, 101509.5000, 201498.7188,\n",
      "        125750.7031, 230585.4375, 201969.8906, 176159.2031, 124023.1406,\n",
      "        199142.9219, 230585.4375, 123709.0156, 219348.1562, 230585.4375,\n",
      "        105167.7344, 317817.5312, 340507.2812, 310880.7188,  67771.9062,\n",
      "        115099.9844,  59606.4688, 230585.4375, 256018.6406, 234489.8125,\n",
      "        172619.9375, 310932.4062, 230585.4375, 230585.4375, 126064.8125,\n",
      "        175373.9375, 257898.2969, 201341.6719, 199299.9688, 136496.2656,\n",
      "        217777.6250, 179629.6719, 106424.1562, 125945.5312, 326272.7188,\n",
      "        317817.5312, 321070.0938, 327355.6562,  68400.1250, 230585.4375,\n",
      "         59920.5664, 168447.8125, 201184.6094, 230585.4375, 123551.9844,\n",
      "        211650.4688, 340507.2812, 320418.8438, 339640.2188, 166092.0156,\n",
      "        200085.2344, 253562.7812, 165508.4688, 126535.9844])\n",
      "tensor([230585.4375, 251828.6094, 230585.4375, 200399.3594, 230585.4375,\n",
      "        194509.5000, 322204.7188, 217620.5781, 203993.1250, 348507.2188,\n",
      "        337234.8750, 346577.0000, 347640.0938,  67457.8203, 230585.4375,\n",
      "        175688.0312, 201812.8281, 200085.2344, 240502.8906, 125436.6094,\n",
      "        194038.3438, 235356.9062, 231021.4062, 152579.6406, 326488.5312,\n",
      "        114272.5000, 230585.4375, 230585.4375,  59449.4102, 167348.4375,\n",
      "        200713.4531, 233622.7031, 230585.4375, 116670.5156, 102922.9531,\n",
      "        174745.7188, 167819.5938, 230585.4375, 126221.8906, 133669.3125,\n",
      "        193567.1875, 218091.7344, 230585.4375, 238768.6875, 126064.8125,\n",
      "        230585.4375, 200085.2344, 230585.4375, 176002.1562, 208898.6719,\n",
      "        153521.9531, 230585.4375, 105324.7812, 204464.2812, 223078.2656,\n",
      "        179146.9375, 342241.5000, 348311.2188, 343080.5312, 168133.7031,\n",
      "        103080.0156, 174745.7188, 136339.2188, 169390.1250])\n",
      "tensor([230585.4375, 228703.7812, 230585.4375, 219348.1562, 204778.3906,\n",
      "        257080.0000, 230585.4375, 252972.0000, 124808.4062, 176944.4688,\n",
      "         59606.4688, 230585.4375, 106110.0469, 230585.4375, 123551.9844,\n",
      "        123551.9844, 124494.2812, 103237.0938, 230585.4375, 175216.8750,\n",
      "        230585.4375, 260780.8750, 230585.4375, 194195.4062, 230033.8438,\n",
      "        201027.5625, 274348.0938, 135396.8906, 198514.7031, 202126.9219,\n",
      "        103394.1094, 115728.2031, 115728.2031, 230585.4375, 218876.9844,\n",
      "        103237.0938, 193410.1250, 218876.9844, 230585.4375, 133826.3750,\n",
      "        177415.6250, 230585.4375, 230585.4375, 331005.9375, 211022.2500,\n",
      "        230585.4375, 126378.9219, 323938.9062, 194195.4062, 155176.1250,\n",
      "        210708.1406, 230585.4375, 198514.7031, 230585.4375, 230585.4375,\n",
      "        230585.4375, 115188.0000, 167034.3281, 230585.4375, 251828.6094,\n",
      "        123866.0781, 178687.3438, 240559.5000, 218876.9844])\n",
      "tensor([206663.0156, 136653.3125, 125122.5000, 259908.8281, 251237.8125,\n",
      "        176944.4688, 253839.1094, 238825.2969, 224177.6250, 144150.7656,\n",
      "        134925.7344, 101823.5781, 230585.4375, 177886.7812, 235356.9062,\n",
      "        230585.4375, 105010.6719, 223392.3750, 222764.1562, 124651.3438,\n",
      "         59449.4102, 230585.4375, 298792.9688,  89332.7656, 230585.4375,\n",
      "        115885.2344,  60391.7266, 237091.1094, 230585.4375, 222764.1562,\n",
      "        230585.4375, 230585.4375, 103551.1719, 230585.4375, 178059.1406,\n",
      "        230585.4375, 218562.8906, 230585.4375, 210708.1406, 223863.5312,\n",
      "        225434.0625, 223863.5312, 230585.4375, 166406.1250, 230585.4375,\n",
      "        175373.9375, 232755.5938, 230585.4375, 230585.4375, 230585.4375,\n",
      "        230585.4375, 123709.0156, 134925.7344, 123709.0156,  89960.9688,\n",
      "        225277.0000, 230585.4375, 177729.7188, 125750.7031, 230585.4375,\n",
      "        125436.6094, 253839.1094, 230585.4375, 250641.1250])\n",
      "tensor([217306.4688, 230585.4375, 287774.1875,  68400.1250, 176630.3438,\n",
      "        115057.7969, 177572.6875, 134925.7344, 230585.4375, 230585.4375,\n",
      "        169076.0312, 230585.4375, 165508.4688, 326670.4375, 241970.1250,\n",
      "        357771.9688, 327423.3750, 209765.8281, 225119.9375, 276082.2812,\n",
      "        264244.3125, 175688.0312, 252104.8906, 230585.4375, 124965.4375,\n",
      "        230585.4375, 230585.4375, 303995.5938,  89357.1250,  57278.4453,\n",
      "        230585.4375, 230585.4375, 136182.1562, 245758.8750, 200556.3906,\n",
      "        176944.4688, 135711.0000, 179158.5000, 152893.7344, 204778.3906,\n",
      "        230585.4375, 199299.9688, 166406.1250, 230585.4375, 175373.9375,\n",
      "        230585.4375, 231418.8438, 230585.4375, 324936.2188, 209451.7188,\n",
      "        239532.3594, 248749.7656, 266160.3438, 237484.0625, 248749.7656,\n",
      "        257967.1406, 179461.0625, 340507.2812, 229876.7969, 199457.0312,\n",
      "        259041.7188, 199614.0781, 126221.8906, 102137.7031])\n",
      "tensor([199457.0312, 227918.5000, 230585.4375, 265136.1875, 248788.2812,\n",
      "        247764.1250, 269232.7812, 254894.6875, 266160.3438, 262063.7656,\n",
      "        243667.5156, 255918.8281, 240556.5156, 240556.5156, 255918.8281,\n",
      "        172382.5156, 313482.0312, 297859.8125, 265750.9688, 124965.4375,\n",
      "        250961.5000, 230585.4375, 135553.9531, 201812.8281, 123709.0156,\n",
      "        353436.4375, 230585.4375, 153207.8438,  90589.1875, 254894.6875,\n",
      "        247764.1250, 247764.1250, 245802.7031, 198828.8281, 315267.9062,\n",
      "        208666.4688, 240556.5156,  89043.0000, 230585.4375, 167236.0469,\n",
      "        123709.0156, 250641.1250, 237958.2188, 224334.6875, 225277.0000,\n",
      "        125436.6094, 230585.4375, 176944.4688, 124337.2500, 136496.2656,\n",
      "        231418.8438, 253562.7812, 124023.1406, 168447.8125, 231888.5000,\n",
      "        217620.5781, 230585.4375,  88885.9688, 340479.2500, 133826.3750,\n",
      "        134611.6250, 228860.8281, 223392.3750, 327355.6562])\n",
      "tensor([244068.5156, 116199.3750, 115188.0000, 230585.4375, 124808.4062,\n",
      "        201969.8906, 230585.4375, 230585.4375, 126064.8125, 345632.5625,\n",
      "        209526.8906, 369621.1250, 238508.2031, 230585.4375, 267485.1875,\n",
      "        133669.3125, 230585.4375, 329157.6250, 153993.1094, 194823.6094,\n",
      "        327423.3750, 177902.0625, 209765.8281, 225434.0625, 145250.1250,\n",
      "        262282.5625, 230585.4375, 230585.4375, 175059.8281, 230585.4375,\n",
      "        201655.7656, 230585.4375, 230585.4375, 125436.6094, 135082.7812,\n",
      "        126535.9844, 249227.2969, 229489.0312, 331758.9062, 217463.5156,\n",
      "        230585.4375, 230585.4375, 228389.6562, 247725.6094, 230585.4375,\n",
      "        271820.6875, 230585.4375, 230585.4375, 134611.6250, 230585.4375,\n",
      "        230585.4375, 172539.5781, 293524.3125, 230585.4375, 269214.4062,\n",
      "         60077.6250, 125593.6562, 262233.7812, 230585.4375, 230585.4375,\n",
      "        201341.6719, 219348.1562, 244691.6719, 223392.3750])\n",
      "tensor([343080.5312, 178515.0000, 114942.9219, 218248.7969, 238825.2969,\n",
      "         67143.7188, 176787.4062, 202126.9219, 126535.9844, 113229.0312,\n",
      "        224962.9062, 204247.8281, 311747.8438, 123866.0781, 125122.5000,\n",
      "        103394.1094, 112914.9062, 230585.4375, 111658.5000, 125750.7031,\n",
      "        230585.4375, 230585.4375, 230585.4375, 262515.0625,  60862.8984,\n",
      "        167191.3906, 230585.4375, 341297.0625, 374823.6875, 324805.9688,\n",
      "         68196.9922, 312614.9375, 318684.6562, 302195.2812, 230585.4375,\n",
      "        115728.2031, 124337.2500, 245767.3281, 175059.8281, 317999.4375,\n",
      "        370488.2188, 238825.2969, 153836.0625, 326540.2188, 193410.1250,\n",
      "        223392.3750, 230585.4375, 254284.4375, 230585.4375, 230585.4375,\n",
      "        177258.5625, 230585.4375, 103080.0156, 167034.3281, 236224.0000,\n",
      "        314531.0312, 209608.7812, 239570.8906,  88728.9062,  68825.2031,\n",
      "        230585.4375, 266618.0938, 264878.9062, 126221.8906])\n",
      "tensor([ 60391.7266, 235815.7969, 176944.4688, 200399.3594, 113801.3438,\n",
      "        175059.8281, 230585.4375, 230585.4375, 124023.1406, 230585.4375,\n",
      "        263377.2188, 125122.5000, 329271.7500, 230585.4375, 393032.8125,\n",
      "        369621.1250, 217777.6250, 230585.4375, 255957.3750, 249773.9219,\n",
      "        240556.5156,  64215.2695, 322153.0312, 317817.5312, 230585.4375,\n",
      "        295258.4688, 113801.3438, 114471.7812, 200399.3594, 230585.4375,\n",
      "        178200.8906, 102608.8594, 136339.2188, 113229.0312, 123866.0781,\n",
      "        111187.3281, 230585.4375, 251822.2031, 355248.0312, 230585.4375,\n",
      "        152893.7344, 271281.0938, 261039.5938, 333542.4375, 337877.9375,\n",
      "        230585.4375, 114314.7188, 101352.4219, 136496.2656, 168021.3125,\n",
      "        168761.9062, 230585.4375, 209922.8750, 269219.3438, 251872.4219,\n",
      "        114115.4375, 230585.4375, 177258.5625, 112129.6562,  61648.1562,\n",
      "        111187.3281, 230585.4375, 334360.2188, 327355.6562])\n",
      "tensor([230585.4375, 230585.4375, 115885.2344, 201498.7188, 368754.0312,\n",
      "        237091.1094, 217306.4688, 322334.9375, 230585.4375, 256942.9688,\n",
      "        224648.7812, 207231.8438,  89357.1250, 247493.0938, 136339.2188,\n",
      "        174745.7188, 230585.4375, 134925.7344, 114785.8750, 124180.1719,\n",
      "        201655.7656, 296338.2500, 167505.5000, 200085.2344, 332626.0312,\n",
      "        294457.4688, 302261.3750, 218405.8281, 343898.3438,  88728.9062,\n",
      "         88885.9688, 320418.8438, 177101.5156, 114785.8750, 217777.6250,\n",
      "        345632.5625, 350835.1250, 153207.8438, 241580.6719, 205818.3594,\n",
      "         68196.9922, 345038.7812, 319551.7500, 230585.4375, 247536.9219,\n",
      "        113071.9688, 237034.5000, 176159.2031, 235356.9062, 194509.5000,\n",
      "        381760.5312, 194823.6094, 295578.0625, 354380.8750, 106549.2812,\n",
      "        260543.4219, 246669.8281, 230585.4375, 335276.6250, 124651.3438,\n",
      "        168918.9688, 230585.4375, 288084.0000, 288534.3125])\n",
      "tensor([230585.4375,  60391.7266, 316838.5312, 112286.6875, 392165.7188,\n",
      "        240559.5000, 179001.4375, 230585.4375, 230585.4375, 239532.3594,\n",
      "        246701.4531, 270256.9688, 230585.4375, 235300.2812, 230585.4375,\n",
      "        112757.8750, 265111.4375, 136025.1094, 283110.9062, 179472.5938,\n",
      "        158089.0469, 224334.6875, 286039.9688, 111658.5000, 218876.9844,\n",
      "        385228.9375, 172696.6250, 292657.1875, 230585.4375,  60705.8398,\n",
      "        217463.5156,  68086.0234, 230585.4375, 199457.0312,  98851.4844,\n",
      "        169547.1719, 168761.9062, 116827.5625, 101823.5781, 230585.4375,\n",
      "        209137.6250, 230585.4375,  59920.5664, 200399.3594, 126693.0312,\n",
      "        231021.4062, 312614.9375, 289508.3750, 114272.5000, 115099.9844,\n",
      "        173532.9062, 173061.7656, 131727.5625, 171334.1875, 171648.2656,\n",
      "        172433.5625, 129842.9219, 171805.3281, 173375.8594, 172747.6406,\n",
      "        171334.1875, 171648.2656, 131570.5000, 173847.0156])\n",
      "tensor([171491.2344, 172747.6406, 173061.7656, 129999.9844, 172747.6406,\n",
      "        172904.7031, 131884.6094, 173532.9062, 131099.3438, 171491.2344,\n",
      "        131256.4062, 173532.9062, 172276.4844, 172590.6094, 172904.7031,\n",
      "        171177.1094, 130785.2344, 172747.6406, 173375.8594, 171020.0781,\n",
      "        171962.3906, 172276.4844, 173689.9844, 131413.4531, 171491.2344,\n",
      "        173689.9844, 171334.1875, 132512.8281, 130471.1406, 171334.1875,\n",
      "        173375.8594, 285065.9062, 230585.4375, 230585.4375, 172276.4844,\n",
      "         88885.9688, 310880.7188, 235815.7969, 283978.0312, 114272.5000,\n",
      "        123551.9844, 246701.4531, 225277.0000, 206760.6875,  64215.2695,\n",
      "         68354.0469,  67928.9844, 277908.2812, 115057.7969, 230585.4375,\n",
      "        103394.1094, 105638.8906, 230585.4375,  60862.8984,  61491.0859,\n",
      "        124180.1719, 168133.7031, 133983.4062, 236839.9688, 250641.1250,\n",
      "        219034.0469, 299044.9375, 295020.8438, 308104.5000])\n",
      "tensor([133669.3125, 353330.1875, 246701.4531, 248749.7656, 223392.3750,\n",
      "        321285.9375, 338745.0000, 201812.8281, 175059.8281, 116827.5625,\n",
      "        199614.0781, 167819.5938, 293516.1250, 252775.3438, 257967.1406,\n",
      "        206191.8594,  65157.5859, 348311.2188, 259442.8125, 230585.4375,\n",
      "        351595.9688, 115414.0781, 113487.2500, 316775.5000, 135239.8438,\n",
      "        240646.5469, 233566.0938, 341018.1250, 288639.7812, 316775.5000,\n",
      "        288951.1250, 253960.5469, 230405.0156, 179472.5938, 285831.8438,\n",
      "        245677.2969, 171283.1406, 344842.7500, 126693.0312, 232453.3438,\n",
      "         59449.4102, 114900.7344, 297699.2812, 201969.8906, 230585.4375,\n",
      "        230585.4375, 178989.9062, 298566.3750, 285933.0312, 279642.5000,\n",
      "        201812.8281, 200242.2969, 299356.3438, 123866.0781, 176159.2031,\n",
      "        293590.3438, 230585.4375, 179629.6719, 230585.4375, 209137.6250,\n",
      "        208823.5156, 248749.7656, 245677.2969, 238508.2031])\n",
      "tensor([ 71696.9219, 290373.9375, 336682.6250, 230585.4375,  61334.0547,\n",
      "        135711.0000, 178357.9375, 304558.9375, 115728.2031, 225277.0000,\n",
      "         88885.9688, 230585.4375, 295471.1562, 136496.2656, 309838.6875,\n",
      "        204621.3281, 166136.6719, 319376.8125, 230585.4375, 230585.4375,\n",
      "        105952.9844, 271319.6562, 172853.6719, 324603.5312, 230585.4375,\n",
      "        298566.3750, 235815.7969, 125907.7656, 230585.4375, 230585.4375,\n",
      "        230405.0156, 219348.1562, 179158.5000, 235356.9062, 178059.1406,\n",
      "        210626.2656, 267184.5000,  68668.1562, 329830.9375, 230585.4375,\n",
      "        329806.1562, 316488.2500, 200556.3906, 199299.9688, 165822.5625,\n",
      "        262233.7812, 103551.1719, 232453.3438, 174745.7188, 227332.5625,\n",
      "        102608.8594, 111972.6094, 201498.7188, 270256.9688,  68668.1562,\n",
      "        319400.9062, 322557.9688, 244080.5156, 230585.4375, 199457.0312,\n",
      "        349861.8125, 296755.0312, 112286.6875, 239622.4062])\n",
      "tensor([238508.2031, 349178.2812,  68243.0938, 339612.0938, 259681.2812,\n",
      "        335008.7188, 315065.4375, 247152.9844, 135868.0469, 308971.5625,\n",
      "        124965.4375, 284615.6250, 201655.7656, 354303.5625, 392165.7188,\n",
      "        300527.1562, 264112.0312,  74865.7969, 245104.6875, 201027.5625,\n",
      "        230585.4375, 230585.4375, 282243.7812, 315908.3750, 103394.1094,\n",
      "        126221.8906, 201184.6094, 116513.4531, 217620.5781, 152736.6875,\n",
      "        300692.9062, 172934.0469, 228232.6094, 230585.4375, 240556.5156,\n",
      "        223863.5312,  67771.9062, 254322.0625, 261491.1250, 230585.4375,\n",
      "        329806.1562, 290055.8438, 316799.6250, 323425.0625, 308104.5000,\n",
      "        230585.4375, 284845.0938, 314237.2500, 230585.4375, 358532.8125,\n",
      "        201812.8281, 167191.3906, 167079.0000, 200556.3906, 323071.7812,\n",
      "        155333.1875, 299660.0625, 230585.4375, 219505.2031, 105167.7344,\n",
      "        317601.7188, 312399.0938, 293736.9375, 230585.4375])\n",
      "tensor([300300.5938, 230585.4375, 230585.4375, 126221.8906,  99008.5469,\n",
      "        230585.4375, 258845.0469, 382627.5938, 235356.9062, 230585.4375])\n",
      "tensor(43820.8828)\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Set model to eval mode\n",
    "\n",
    "MaeList = []\n",
    "\n",
    "with torch.no_grad(): # Deactivate gradients for the following code\n",
    "    for numerical_data,categorical_data0, categorical_data1,labels in test_loader:\n",
    "\n",
    "        # Determine prediction of model on dev set\n",
    "        inputs = torch.cat([numerical_data, categorical_data0, categorical_data1],dim=1)\n",
    "        # print(inputs[0])\n",
    "        preds = model(inputs)\n",
    "        # print(preds)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "        print(preds)\n",
    "        # print(preds)\n",
    "\n",
    "        # # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "        # true_preds += (preds == data_labels).sum()\n",
    "        # num_preds += data_labels.shape[0]\n",
    "\n",
    "        MaeList.append(mae(labels, preds))\n",
    "MaeValue = sum(MaeList)/len(MaeList)\n",
    "print(MaeValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 2\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 2\n",
      "1 0\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "2 2\n",
      "1 2\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "2 2\n",
      "1 2\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "2 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "2 2\n",
      "2 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 2\n",
      "0 1\n",
      "0 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 2\n",
      "2 2\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "0 0\n",
      "1 2\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "0 0\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "0 0\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "0 0\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "0 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "2 2\n",
      "1 2\n",
      "1 2\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "2 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n",
      "1 2\n",
      "1 2\n",
      "1 1\n",
      "1 2\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "1 2\n",
      "1 1\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1767\n",
      "[2.0 1.0 0.0]\n",
      "[1.0 4.0 3.0 2.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "dft = pd.read_csv(\"test_data.csv\")\n",
    "print(len(dft))\n",
    "categorical_columns = [\"HallwayType\", \"SubwayStation\"]\n",
    "dataType = \"TimeToBusStop\"\n",
    "dft.loc[dft[dataType] == '0~5min', dataType] = np.float64(2.0)\n",
    "dft.loc[dft[dataType] == '5min~10min', dataType] = np.float64(1.0)\n",
    "dft.loc[dft[dataType] == '10min~15min', dataType] = np.float64(0.0)\n",
    "print(dft[dataType].unique())\n",
    "\n",
    "dataType = \"TimeToSubway\"\n",
    "dft.loc[dft[dataType] == 'no_bus_stop_nearby', dataType] = np.float64(0.0)\n",
    "dft.loc[dft[dataType] == '0-5min', dataType] = np.float64(4.0)\n",
    "dft.loc[dft[dataType] == '5min~10min', dataType] = np.float64(3.0)\n",
    "dft.loc[dft[dataType] == '10min~15min', dataType] = np.float64(2.0)\n",
    "dft.loc[dft[dataType] == '15min~20min', dataType] = np.float64(1.0)\n",
    "print(dft[dataType].unique())\n",
    "\n",
    "dft.HeatingType = (dft.HeatingType==dft[\"HeatingType\"].unique()[0]).astype(int)\n",
    "dft.AptManageType = (dft.AptManageType==dft[\"AptManageType\"].unique()[0]).astype(int)\n",
    "\n",
    "categorical_values0t = pd.get_dummies(dft[categorical_columns[0]])\n",
    "categorical_values1t = pd.get_dummies(dft[categorical_columns[1]])\n",
    "\n",
    "dft.drop(columns=categorical_columns,inplace=True)\n",
    "\n",
    "dft = dft.astype(float)\n",
    "\n",
    "numerical_datat = torch.from_numpy(dft.values).float()\n",
    "scaler = StandardScaler()\n",
    "numerical_datat = scaler.fit_transform(numerical_datat)\n",
    "categorical_data0t = torch.from_numpy(categorical_values0t.values).float()\n",
    "categorical_data1t = torch.from_numpy(categorical_values1t.values).float()\n",
    "validate_dataset = data.TensorDataset(torch.from_numpy(numerical_datat).float(),categorical_data0t,categorical_data1t)\n",
    "validate_loader = data.DataLoader(validate_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([180438.0156, 302277.2812, 341071.1250, 173808.9688, 220664.8125,\n",
      "        326530.6875, 225410.9844,  63139.1641, 204960.7656, 233004.6719,\n",
      "        138048.3125, 182504.0625, 176500.0469, 181232.6406, 258750.0469,\n",
      "        308125.8438, 211256.7500, 230585.4375, 256058.6875, 230585.4375,\n",
      "        172691.3125, 139001.8594, 147588.6719, 173808.9688, 337060.0312,\n",
      "        211771.7656, 116965.9531, 246149.1562, 178089.3281, 331799.0625,\n",
      "        177338.6875, 202148.7344, 234998.0312, 160673.5781, 171425.0781,\n",
      "        129828.9688, 255637.9844, 179484.4688, 104751.9219, 260934.4062,\n",
      "        230585.4375, 109619.0781, 234998.0312, 230585.4375, 230585.4375,\n",
      "        236729.6875, 230585.4375, 224457.4375, 211415.6719, 230585.4375,\n",
      "        255583.2031, 357609.4062, 176182.2031, 233211.1562, 201830.8906,\n",
      "        140591.1250, 230585.4375, 203689.3750, 230585.4375, 128557.5625,\n",
      "        176182.2031, 139160.7812, 120334.0938, 161817.3750])\n",
      "tensor([202784.4531, 337941.1250, 106182.2656,  92834.0469, 178248.2500,\n",
      "        240262.6719,  69235.5234, 171425.0781,  62344.5352, 327219.2500,\n",
      "        301824.8125, 201830.8906, 255583.2031, 171107.2188, 206391.1094,\n",
      "        230585.4375, 206867.8750, 180914.7969, 230585.4375, 176976.8281,\n",
      "        282869.6875, 260025.1875, 136420.8125, 230585.4375, 179166.6094,\n",
      "        279812.3750, 176182.2031, 234966.0312, 239385.2344, 355555.5312,\n",
      "        202943.3750, 139955.4062, 277605.0625, 269677.0312, 230585.4375,\n",
      "        211574.6094,  63872.5703, 230585.4375, 230585.4375, 205119.7031,\n",
      "        260025.1875, 104434.0781, 212210.3125,  61708.8438, 202625.5156,\n",
      "        118078.4062, 118873.0469, 255629.1719, 242017.5469, 356865.0625,\n",
      "        327148.0312, 212369.2344, 203848.2969, 239930.9375, 136102.9531,\n",
      "        230585.4375,  61867.7812, 317707.4375, 350589.8438, 259817.7969,\n",
      "        331623.5312,  92493.4688, 227000.2500, 230587.5781])\n",
      "tensor([117442.6875, 302441.1875, 180755.8750,  62185.6289,  61708.8438,\n",
      "         67296.7109, 332871.7188, 230585.4375, 226523.4688, 230585.4375,\n",
      "        161468.2031, 259568.4531, 140591.1250, 176976.8281, 128080.7969,\n",
      "        236720.9219, 230585.4375, 330917.9062, 260822.7812, 170630.4375,\n",
      "        230585.4375, 317756.2812, 213142.5469, 255021.0625, 360579.1875,\n",
      "        159878.9375, 138842.9375, 230585.4375, 180006.9531,  92652.4219,\n",
      "         91244.7812, 230585.4375, 213481.7188, 321269.7500,  61867.7812,\n",
      "        126809.3906, 106341.1719,  62503.4727, 175705.4219, 126809.3906,\n",
      "        301514.0000, 176341.1250, 179484.4688, 274677.9375, 140591.1250,\n",
      "        242212.6406, 126809.3906,  92357.2656, 255637.9844, 127604.0156,\n",
      "         63077.9414, 230585.4375, 108824.4531, 361456.6250, 173491.1094,\n",
      "        203848.2969, 362575.0000, 205437.5469, 133401.2031, 234315.6562,\n",
      "        292739.5938, 127127.2344, 233882.1094, 227159.1875])\n",
      "tensor([110545.3906, 201671.9688,  92970.2500, 309460.7188, 230585.4375,\n",
      "        212528.1562, 127921.8594, 295358.3438, 206271.6094, 302046.5312,\n",
      "        362874.0312, 173332.2031, 355555.5312, 255780.0312, 230585.4375,\n",
      "        128398.6406, 393055.5312, 278396.7188, 138207.2344, 176341.1250,\n",
      "        241335.1875, 317496.1562, 177771.4688, 221459.4375, 171584.0156,\n",
      "        255672.3438, 104434.0781, 220982.6562, 230585.4375, 180914.7969,\n",
      "        230585.4375, 221618.3594,  92811.3125, 179802.3281, 128239.7188,\n",
      "        303579.6875, 176500.0469, 211256.7500, 348090.6562, 237607.1250,\n",
      "        308188.6562, 178970.5938, 263931.8750, 176658.9844, 128875.4219,\n",
      "        230585.4375, 236729.6875, 108824.4531, 230585.4375, 221618.3594,\n",
      "        202784.4531, 177294.6875, 371996.9375, 267305.2500, 230585.4375,\n",
      "        180755.8750, 160037.8594,  92811.3125, 251250.7500, 139160.7812,\n",
      "        366383.8125,  62344.5352, 316022.8438, 263078.2188])\n",
      "tensor([302391.4688, 160514.6406, 230585.4375, 326946.3125, 248221.8906,\n",
      "        176817.9062, 171107.2188, 177135.7656, 257392.8594, 106182.2656,\n",
      "        159878.9375, 252919.1250,  62601.1602, 230585.4375, 139796.4844,\n",
      "        230585.4375, 230585.4375, 211892.4531, 328701.1875, 270586.2188,\n",
      "        120016.2344, 139160.7812, 230585.4375, 239385.2344, 203848.2969,\n",
      "        295904.4688, 230585.4375, 139001.8594, 258270.2812, 176023.2812,\n",
      "        182889.4688, 118873.0469,  62980.2539, 384281.1250, 328289.2812,\n",
      "        230585.4375, 336888.2188, 160673.5781, 230585.4375, 173808.9688,\n",
      "        119539.4688, 230585.4375, 269590.5312, 127286.1719, 312029.7812,\n",
      "        230585.4375, 135944.0312, 335305.1562, 271217.8438, 235875.4531,\n",
      "        225887.7656, 230585.4375, 268713.0938,  66660.9922, 173967.8906,\n",
      "        139001.8594, 233219.9219, 138684.0000, 234998.0312,  92652.4219,\n",
      "        324313.9688, 238702.8594,  63615.9453, 213799.5625])\n",
      "tensor([249561.8281,  63774.8828, 177930.4062, 325653.2500, 361996.5938,\n",
      "        236752.9062, 230585.4375, 116807.0000, 108347.6719, 328855.9375,\n",
      "        352682.1562, 324515.6875, 128239.7188, 171419.9062, 230585.4375,\n",
      "        127762.9375, 230585.4375, 239385.2344, 212369.2344, 160673.5781,\n",
      "        254440.0938, 235875.4531, 276727.5938,  67296.7109, 330921.5938,\n",
      "         62919.0078, 160673.5781, 230585.4375, 202307.6719, 230585.4375,\n",
      "        353559.5938, 342152.9062, 127604.0156, 221300.5156, 325656.9688,\n",
      "        206056.9688, 180596.9531, 230585.4375, 274095.2500, 201671.9688,\n",
      "         63615.9453, 343030.3438, 205119.7031, 387790.8750, 211733.5312,\n",
      "        230585.4375, 138048.3125, 129511.1250, 129670.0625, 226364.5469,\n",
      "        242017.5469, 139001.8594, 105546.5312, 230585.4375, 267044.7188,\n",
      "        316416.9688, 177135.7656, 230585.4375, 230585.4375, 139955.4062,\n",
      "        127127.2344, 139319.7031, 244076.4219, 363452.5000])\n",
      "tensor([171260.9688, 277787.0625, 226046.6875, 261725.3281, 247477.2812,\n",
      "        242017.5469, 230585.4375, 206073.2500, 276302.6250, 255672.3438,\n",
      "        118744.8125, 207701.9531, 129511.1250,  63139.1641, 230585.4375,\n",
      "        260168.7969, 118873.0469, 323024.5938, 161468.2031, 230610.8125,\n",
      "        327978.4688, 203261.2188, 329851.5625, 355314.5312, 326729.6562,\n",
      "        230585.4375, 212051.3750, 355314.5312, 180006.9531, 230585.4375,\n",
      "         63139.1641, 182027.2656, 351600.4062,  69394.4375, 105864.4219,\n",
      "        225728.8438, 331795.3438, 129352.2031, 230585.4375, 230585.4375,\n",
      "        264314.2500, 108440.1250, 109142.2969, 230585.4375, 362874.0312,\n",
      "        230585.4375, 230585.4375, 230585.4375, 181709.4219, 202943.3750,\n",
      "        324775.8125, 227000.2500, 206867.8750, 270586.2188, 173808.9688,\n",
      "        171742.9375, 139319.7031, 321266.0625, 172060.7969, 202784.4531,\n",
      "        206073.2500, 104275.1406, 178248.2500, 259147.7188])\n",
      "tensor([225093.1406, 230585.4375, 299808.9062, 220982.6562, 267076.4688,\n",
      "        280474.3125, 140273.2656, 180279.1094, 362334.0625, 226841.3281,\n",
      "        253005.6562, 201830.8906, 201989.8281, 202466.5938, 270467.9688,\n",
      "        235875.4531, 333378.4375, 262895.5000, 140432.2031, 230585.4375,\n",
      "        230585.4375, 110545.3906,  63774.8828,  92675.1250, 206708.9531,\n",
      "        336010.8125, 233004.6719, 119010.6562, 310338.1562, 109909.6875,\n",
      "        109936.9375, 138684.0000, 105864.4219, 128875.4219, 174346.5156,\n",
      "        353222.1562, 327408.1250, 230585.4375, 139637.5625, 319322.2812,\n",
      "        128875.4219, 205159.1406, 207185.7344,  92198.3438, 230585.4375,\n",
      "        230585.4375, 333550.2188, 253005.6562, 347080.0938, 260854.1719,\n",
      "        129352.2031,  92970.2500, 250459.0938, 230585.4375, 231488.2656,\n",
      "        109619.0781, 239385.2344, 331795.3438, 119010.6562, 234974.7969,\n",
      "        138684.0000,  63139.1641,  91880.4844, 230585.4375])\n",
      "tensor([137571.5312, 318633.7188, 175546.5000, 172378.6406, 230585.4375,\n",
      "        172219.7188, 180438.0156, 211574.6094, 275732.6250, 171584.0156,\n",
      "        127604.0156, 271431.9062, 160832.5000, 183684.0938, 180279.1094,\n",
      "         62344.5352, 225728.8438, 230585.4375, 230585.4375, 276610.0625,\n",
      "        230585.4375, 309397.4375, 205278.6250, 236729.6875, 361996.5938,\n",
      "        180279.1094, 237630.3594, 305023.7500,  67964.1094, 138207.2344,\n",
      "        313108.9375, 308533.5312, 259147.7188, 171266.1562, 230585.4375,\n",
      "        139478.6562, 262731.0312, 119857.3125, 106023.3281, 230585.4375,\n",
      "        173491.1094, 220505.8750, 128239.7188,  96681.5781, 109115.0469,\n",
      "        118426.9844, 138684.0000, 183366.2500, 127604.0156, 139001.8594,\n",
      "        325653.2500, 230585.4375, 128080.7969, 183366.2500,  62026.6914,\n",
      "        230585.4375, 106500.1094, 327408.1250, 207344.6562, 139478.6562,\n",
      "        161150.3438, 230585.4375, 272222.8125, 303255.3438])\n",
      "tensor([171326.9219, 110863.2188, 335305.1562, 140432.2031, 349506.6875,\n",
      "        176023.2812, 336010.8125, 129511.1250, 274972.7188, 180006.9531,\n",
      "        235875.4531, 170625.2812, 179484.4688, 220346.9531, 298931.4688,\n",
      "        180596.9531, 250490.5000, 181232.6406, 260822.7812, 287130.0625,\n",
      "        267922.1562, 140273.2656, 177771.4688, 230585.4375, 329163.0000,\n",
      "        306370.9688, 230585.4375, 224616.3594, 230585.4375, 344960.6875,\n",
      "        120651.9375, 230585.4375, 220982.6562, 171584.0156, 175705.4219,\n",
      "        252128.2031, 203261.2188, 294088.4062, 177930.4062, 256058.6875,\n",
      "        206232.1719, 207026.7969, 230585.4375, 204166.1406, 160355.7188,\n",
      "        350290.8125, 307262.7812, 391300.6562, 212528.1562, 225728.8438,\n",
      "        230585.4375, 276750.6562, 224457.4375, 173173.2656, 180438.0156,\n",
      "        233882.1094, 179166.6094, 207964.0781, 139637.5625, 206907.3125,\n",
      "        272341.1250, 289701.1875, 105864.4219, 335116.2188])\n",
      "tensor([201989.8281, 330239.4062, 201830.8906, 110863.2188, 230585.4375,\n",
      "        233219.9219, 276727.5938, 179802.3281, 181709.4219, 139319.7031,\n",
      "        265289.8438, 255640.9219, 171803.6875, 179802.3281, 355854.5000,\n",
      "        280896.1562, 230585.4375,  68758.7422, 129034.3438, 208440.8594,\n",
      "        125287.2656, 230585.4375, 226523.4688, 224616.3594, 258096.0625,\n",
      "        295027.0312, 110807.5156, 268459.7500, 237630.3594, 353559.5938,\n",
      "        347080.0938, 178970.5938, 201989.8281, 332501.0000, 201989.8281,\n",
      "        319926.7812, 252563.2344, 176500.0469, 106023.3281, 138207.2344,\n",
      "        230585.4375, 239580.2969, 330921.5938, 137571.5312, 118426.9844,\n",
      "        225252.0625, 104910.8594, 160991.4219, 201989.8281, 135626.1719,\n",
      "        225410.9844, 237630.3594, 136420.8125, 336888.2188, 137889.3750,\n",
      "        230585.4375, 230585.4375, 268799.5625, 181868.3594, 353374.9062,\n",
      "        230585.4375, 207026.7969, 257713.6719, 119221.6094])\n",
      "tensor([230585.4375, 234998.0312, 139319.7031, 221141.5781, 248161.7031,\n",
      "        127604.0156, 230585.4375, 230585.4375, 128716.5000, 201671.9688,\n",
      "         62503.4727, 184160.8750, 297126.8125, 206867.8750, 180755.8750,\n",
      "        179166.6094,  63713.6328, 202943.3750, 201671.9688, 104910.8594,\n",
      "        335875.4688, 105864.4219, 211415.6719, 253883.0938, 230585.4375,\n",
      "        175705.4219, 237630.3594, 293635.9375, 139001.8594, 204642.9219,\n",
      "        128398.6406, 252041.6875, 127762.9375, 213142.5469,  66975.6953,\n",
      "        175546.5000, 171425.0781, 230585.4375, 171266.1562, 230585.4375,\n",
      "        230585.4375, 180914.7969, 230585.4375, 230585.4375, 230585.4375,\n",
      "        291295.5000,  93288.0938, 254604.5625, 182345.1406, 161150.3438,\n",
      "        275764.3750, 254143.6250, 146158.3438,  66975.6953, 230585.4375,\n",
      "         63077.9414, 335133.3125, 238507.7969, 242895.0000, 326946.3125,\n",
      "        272254.2188, 127921.8594, 230585.4375, 177771.4688])\n",
      "tensor([220188.0156,  91880.4844, 230585.4375, 309003.3125, 307262.7812,\n",
      "        254604.5625, 133719.0625, 175705.4219, 307248.4062, 324313.9688,\n",
      "        176182.2031, 255637.9844, 312907.2188, 313798.1875, 172055.5938,\n",
      "        230585.4375, 230585.4375, 175864.3594, 180914.7969, 173650.0469,\n",
      "        175864.3594, 173967.8906, 140273.2656, 230585.4375,  66819.9297,\n",
      "        177930.4062, 230585.4375, 238507.7969, 331623.5312, 252367.3594,\n",
      "        327607.0938, 241140.1250, 230585.4375, 172696.4844, 233243.1406,\n",
      "        294805.2812, 312970.5000, 234966.0312, 351804.7500, 171260.9688,\n",
      "        230585.4375, 230585.4375, 203420.1562, 288884.9375, 230585.4375,\n",
      "        203848.2969, 230585.4375, 214731.7969, 177453.6250, 230585.4375,\n",
      "        233718.3750, 176182.2031, 182821.9219, 226205.6094,  67452.4688,\n",
      "        270150.0938, 230585.4375, 208440.8594, 183684.0938, 211574.6094,\n",
      "        160029.4062, 109591.8281, 301500.4375, 230585.4375])\n",
      "tensor([129670.0625, 171107.2188, 346540.0625, 234120.5781, 120016.2344,\n",
      "        230585.4375,  92675.1250, 202148.7344, 254705.7656, 230585.4375,\n",
      "        205914.3281, 110386.4375, 230585.4375, 179484.4688, 174187.5938,\n",
      "        230585.4375, 264325.9062, 231488.2656, 270499.7188, 204801.8438,\n",
      "        396565.3125, 202307.6719, 259408.2656, 318373.5938, 330456.0938,\n",
      "        127286.1719, 230585.4375, 230585.4375, 128875.4219, 139637.5625,\n",
      "        316900.2500, 337765.6562, 245416.3594, 176341.1250, 177771.4688,\n",
      "        219711.2344, 230585.4375, 172219.7188, 139160.7812,  73779.6953,\n",
      "        230585.4375, 230585.4375, 127127.2344, 230585.4375, 230585.4375,\n",
      "        374629.2500, 256677.2969, 332501.0000, 307089.4375, 230585.4375,\n",
      "        127286.1719, 127921.8594, 226046.6875, 230585.4375, 242895.0000,\n",
      "        230585.4375, 230585.4375, 230805.8906, 175546.5000, 252563.2344,\n",
      "        274095.2500, 266167.2812, 230585.4375, 256515.4219])\n",
      "tensor([230585.4375,  63298.1016, 296648.8125, 230585.4375,  68758.7422,\n",
      "        230585.4375, 230585.4375, 205318.0469, 175546.5000, 137730.4531,\n",
      "        316022.8438, 120175.1719, 213043.1719, 230585.4375, 339520.5312,\n",
      "        207026.7969, 139955.4062, 307248.4062, 363211.5000,  62601.1602,\n",
      "        268182.6875, 179166.6094, 177135.7656, 117601.6250, 146952.9844,\n",
      "        212528.1562, 109591.8281, 202625.5156, 234998.0312, 159720.0156,\n",
      "        133401.2031, 180755.8750, 258781.4531, 211415.6719, 230585.4375,\n",
      "        161309.2812, 235875.4531, 206708.9531, 290639.8125, 203420.1562,\n",
      "        261890.5469, 313784.6562, 259147.7188, 230585.4375, 230585.4375,\n",
      "        263448.4375, 301514.0000, 268459.7500, 176500.0469, 179325.5469,\n",
      "        296720.7500, 105387.6406, 230585.4375, 233004.6719, 230585.4375,\n",
      "        109301.2500, 139637.5625, 205596.4688, 177771.4688, 325464.3750,\n",
      "        211415.6719, 230585.4375, 230585.4375, 204007.2188])\n",
      "tensor([177453.6250, 319511.1562, 138048.3125,  62344.5352, 108665.5312,\n",
      "        346540.0625, 316618.7188, 336182.5625, 137889.3750, 350927.3125,\n",
      "        257745.0938, 230585.4375, 230585.4375, 234966.0312, 355129.7500,\n",
      "        134672.6094, 118426.9844, 207185.7344, 235193.0938, 263277.8750,\n",
      "        181232.6406, 230585.4375, 230585.4375, 230585.4375, 176182.2031,\n",
      "        178089.3281, 178248.2500, 220982.6562, 269113.7188, 201671.9688,\n",
      "        253220.4062, 235875.4531, 230585.4375, 137889.3750, 234998.0312,\n",
      "        208440.8594, 255640.9219, 230585.4375, 230585.4375, 211136.0625,\n",
      "        104910.8594, 211097.8281, 137889.3750, 237825.4219,  62662.4102,\n",
      "        207384.0938, 332365.6875, 219711.2344, 104434.0781,  61708.8438,\n",
      "        129511.1250, 230585.4375, 278057.5000, 104275.1406, 207384.0938,\n",
      "        313847.9375, 171644.7656, 206708.9531, 221777.2812, 140114.3438,\n",
      "        177294.6875, 128080.7969, 128080.7969, 251164.2500])\n",
      "tensor([306212.0312, 352344.7500, 239385.2344, 355854.5000, 206550.0312,\n",
      "        140432.2031, 211097.8281, 211294.9844, 204483.9844, 179166.6094,\n",
      "         92493.4688, 230585.4375,  62344.5352, 202148.7344, 212407.4688,\n",
      "        259147.7188, 230585.4375, 320410.0312, 259786.4062, 334427.6875,\n",
      "        230585.4375,  61708.8438, 177294.6875, 269113.7188, 230585.4375,\n",
      "        323591.2500, 251634.5625, 117124.8438, 230585.4375, 230585.4375,\n",
      "        235875.4531, 106182.2656, 233243.1406, 138366.1562, 230585.4375,\n",
      "        179166.6094, 329780.3438, 230585.4375, 104910.8594, 258302.0469,\n",
      "        161309.2812, 213799.5625, 291003.6250, 214413.9375, 212687.0781,\n",
      "        206056.9688, 221936.2188, 120493.0156, 276728.3125,  92652.4219,\n",
      "        230585.4375, 272254.6250, 104751.9219, 238484.5625, 230585.4375,\n",
      "        173491.1094, 181391.5781, 315145.3750, 235875.4531, 232365.6875,\n",
      "        107383.3438, 232840.9375, 120651.9375, 147270.8125])\n",
      "tensor([230585.4375, 207344.6562, 177135.7656, 140114.3438, 230585.4375,\n",
      "        138842.9375, 212369.2344, 176500.0469, 117760.5625, 172850.2500,\n",
      "        312043.3125,  63298.1016, 171266.1562, 263480.1875, 176817.9062,\n",
      "        176500.0469, 320410.0312, 211256.7500, 234120.5781, 318633.7188,\n",
      "        230585.4375, 205755.4062, 206851.5938, 276727.5938, 127127.2344,\n",
      "        212051.3750, 230585.4375, 230585.4375, 230585.4375, 212665.7656,\n",
      "        319532.5938, 234315.6562, 202784.4531, 127762.9375, 295843.3125,\n",
      "        302702.2500, 278934.9375, 366721.2812, 139796.4844,  75764.1484,\n",
      "        138525.0781, 206391.1094, 230585.4375, 364088.9375, 221459.4375,\n",
      "        204801.8438, 230585.4375, 208178.7344, 265203.3438, 252563.2344,\n",
      "        230585.4375, 230585.4375, 161309.2812, 105546.5312, 252531.8438,\n",
      "         63774.8828, 230585.4375, 206550.0312, 127445.0938,  93310.8281,\n",
      "        242003.7031, 224934.2031, 230585.4375, 233243.1406])\n",
      "tensor([138048.3125, 224298.5000, 312093.0938, 173808.9688, 230585.4375,\n",
      "        230585.4375,  91244.7812, 288741.2500,  92811.3125, 180006.9531,\n",
      "        220982.6562, 139955.4062, 230585.4375, 230585.4375, 318832.6250,\n",
      "        213640.6406, 323902.0312, 160514.6406, 212665.7656, 183843.0156,\n",
      "        230585.4375, 172532.3906, 104275.1406,  61549.9062,  92198.3438,\n",
      "        128398.6406, 230585.4375, 181073.7188, 257549.2031, 119698.3906,\n",
      "        204483.9844,  62662.4102, 234097.3438, 139478.6562, 230585.4375,\n",
      "        230585.4375, 230585.4375, 320958.9375, 126968.3125, 176817.9062,\n",
      "        177930.4062, 236752.9062,  91721.5625, 201830.8906, 139478.6562,\n",
      "        275363.3125, 160514.6406, 252128.2031, 158440.1406, 236752.9062,\n",
      "        221141.5781, 128557.5625, 172537.5625, 177930.4062, 230585.4375,\n",
      "        230585.4375, 281713.9375, 253266.1719, 160355.7188, 230585.4375,\n",
      "        388668.3125, 120334.0938, 295371.9062, 230585.4375])\n",
      "tensor([230585.4375, 105069.7656,  93288.0938, 172537.5625, 136261.8750,\n",
      "        106341.1719, 206550.0312, 129193.2656, 221777.2812, 171896.6875,\n",
      "        202784.4531, 202466.5938, 139001.8594,  66978.8594,  62760.0703,\n",
      "        170307.4375, 308520.0000,  61867.7812, 180279.1094,  61549.9062,\n",
      "        180755.8750, 206867.8750, 267044.7188, 230585.4375, 341258.3438,\n",
      "        206232.1719, 258261.5000, 172121.5469, 234998.0312, 134195.8438,\n",
      "        333361.3750, 128080.7969, 336871.0625, 231683.3281, 211930.6875,\n",
      "        260822.7812, 206533.7500, 179325.5469, 230585.4375, 312029.7812,\n",
      "        271377.1562, 230585.4375,  95487.2188, 346202.6875, 327411.8438,\n",
      "        180596.9531, 266387.0000, 230585.4375, 230585.4375, 173392.9531,\n",
      "        305950.9688, 177771.4688, 106500.1094, 268799.5625, 316878.8750,\n",
      "        129670.0625,  58215.8945, 212824.6875, 227000.2500, 171901.8750,\n",
      "        176658.9844, 225569.9062, 104593.0156, 138525.0781])\n",
      "tensor([110068.6094, 337222.4375, 138842.9375, 230585.4375, 250459.0938,\n",
      "        397442.7500, 260822.7812, 172537.5625, 230585.4375, 212846.0156,\n",
      "        230585.4375, 280237.3438, 230585.4375, 129670.0625, 213163.8594,\n",
      "        249916.5781, 105864.4219, 207185.7344, 275732.6250, 357946.8438,\n",
      "        235193.0938,  63457.0508, 110704.2969,  61549.9062, 180279.1094,\n",
      "        206073.2500, 230585.4375, 206550.0312, 259786.4062,  92811.3125,\n",
      "        201830.8906, 138207.2344, 224616.3594, 118109.1250, 250588.0781,\n",
      "        257392.8594, 202625.5156, 355854.5000, 201671.9688, 117283.7812,\n",
      "        258270.2812, 349172.4375, 172757.2500, 206533.7500, 254303.7969,\n",
      "        230585.4375, 230585.4375, 296720.7500, 109750.7500, 182662.9844,\n",
      "         75821.7031, 170948.2969, 171742.9375, 204801.8438, 118873.0469,\n",
      "        161309.2812, 211574.6094, 171425.0781, 139955.4062, 204166.1406,\n",
      "        129511.1250, 140432.2031, 230585.4375, 354099.6250])\n",
      "tensor([129670.0625, 230585.4375, 118903.7656, 341948.5625, 322164.9062,\n",
      "        139319.7031, 230585.4375,  63139.1641, 313684.0312, 211256.7500,\n",
      "         62980.2539, 292394.6875, 230585.4375, 230585.4375, 347957.5000,\n",
      "        206867.8750, 333550.2188, 128239.7188, 241140.1250, 211574.6094,\n",
      "        320410.0312, 129193.2656, 230585.4375, 201989.8281, 207805.1562,\n",
      "        213799.5625, 313784.6562, 147747.6094, 230585.4375, 230585.4375,\n",
      "        259786.4062, 232840.9375, 230585.4375, 172060.7969, 267072.3750,\n",
      "         61549.9062, 177453.6250, 140114.3438, 128398.6406, 333550.2188,\n",
      "        211256.7500, 349845.5312, 105069.7656, 176500.0469, 282968.9062,\n",
      "        105228.7031, 332672.7812,  92493.4688, 139478.6562, 230585.4375,\n",
      "        330456.0938, 127445.0938, 330040.4688, 204007.2188, 140114.3438,\n",
      "        235875.4531, 128557.5625, 137571.5312, 312029.7812,  62185.6289,\n",
      "        240967.3125, 120016.2344, 109432.8906, 177135.7656])\n",
      "tensor([104751.9219, 118268.0469, 173808.9688, 177020.8438, 179166.6094,\n",
      "        230585.4375, 129193.2656, 374629.2500, 333290.1250, 327219.2500,\n",
      "        175546.5000, 302441.1875, 226046.6875, 160037.8594, 235852.2500,\n",
      "        304132.7812, 203102.2969, 105387.6406, 268077.3438, 172378.6406,\n",
      "        230585.4375, 351467.3125, 363751.4688, 146476.2031,  68123.0469,\n",
      "        295358.3438,  92970.2500, 230585.4375, 306778.6562, 226682.3906,\n",
      "        206692.6719, 173014.3438, 176817.9062, 230585.4375, 176817.9062,\n",
      "        221936.2188, 138207.2344, 258530.8281, 230585.4375, 129193.2656,\n",
      "        207026.7969,  68123.0469, 118426.9844, 105546.5312, 128716.5000,\n",
      "        206550.0312, 179484.4688, 172855.4219, 177135.7656, 230585.4375,\n",
      "        230585.4375, 128239.7188,  69394.4375, 171901.8750, 206391.1094,\n",
      "        238702.8594, 128080.7969, 260902.6250, 253403.7188, 230585.4375,\n",
      "        205914.3281, 180279.1094, 333749.1562, 267076.4688])\n",
      "tensor([129352.2031, 126968.3125,  62185.6289, 276302.6250, 119698.3906,\n",
      "        135467.2500, 176976.8281, 319511.1562, 182186.2031, 128080.7969,\n",
      "        251495.4688, 230585.4375, 357069.4062, 146158.3438, 230585.4375,\n",
      "        253005.6562, 256677.2969, 181550.5000, 126968.3125, 272309.3750,\n",
      "        325653.2500, 212725.3125, 329163.0000, 212846.0156, 235875.4531,\n",
      "        349172.4375, 171742.9375, 261859.1250, 104275.1406, 171578.8438,\n",
      "        230585.4375, 211892.4531, 282591.3750, 171901.8750, 211892.4531,\n",
      "        205437.5469, 172532.3906, 230585.4375, 177294.6875, 333182.5312,\n",
      "        213799.5625,  63457.0508, 170948.2969, 230585.4375, 230805.8906,\n",
      "        309066.0938, 230585.4375, 360241.7188, 213799.5625, 230585.4375,\n",
      "        225252.0625, 342017.5625, 205914.3281, 105387.6406, 230585.4375,\n",
      "        230585.4375, 230585.4375, 352477.8438, 313320.2188, 305042.6875,\n",
      "        315812.5000, 242895.0000, 211574.6094, 175864.3594])\n",
      "tensor([230585.4375, 205476.9844, 139160.7812, 211097.8281, 202784.4531,\n",
      "        179166.6094, 354678.0625, 349172.4375, 175705.4219, 270586.2188,\n",
      "        206867.8750, 260902.6250, 279359.9375, 221141.5781, 256708.7188,\n",
      "        206073.2500, 211574.6094, 176817.9062,  63872.5703, 172537.5625,\n",
      "        230585.4375, 230585.4375, 206073.2500, 160196.7969, 212369.2344,\n",
      "        239385.2344, 175864.3594,  63774.8828, 178970.5938, 184001.9531,\n",
      "        230585.4375, 129511.1250, 230585.4375, 261890.5469, 259132.4375,\n",
      "        202148.7344, 211930.6875, 230585.4375, 182351.1562, 120810.8750,\n",
      "         63872.5703, 353222.1562, 176658.9844, 317756.2812, 140114.3438,\n",
      "        230585.4375, 140114.3438, 117283.7812, 242017.5469, 269060.1250,\n",
      "        128875.4219, 275764.3750, 211097.8281, 139955.4062, 181073.7188,\n",
      "        230585.4375, 305787.0312, 230585.4375, 324313.9688, 230585.4375,\n",
      "        334255.8750, 104275.1406, 318832.6250, 139955.4062])\n",
      "tensor([234315.6562, 230585.4375, 230585.4375, 323919.8125, 129828.9688,\n",
      "        140750.0469, 176500.0469, 353893.8750, 205755.4062, 119380.5312,\n",
      "        140750.0469, 280689.8125, 129828.9688, 338643.0938, 176817.9062,\n",
      "        230585.4375, 256058.6875,  96522.6562, 230585.4375, 230585.4375,\n",
      "        321266.0625, 230585.4375, 371996.9375, 236729.6875, 134354.7500,\n",
      "        220188.0156, 257713.6719, 230585.4375, 266427.7812, 219711.2344,\n",
      "        138525.0781, 363751.4688, 134195.8438, 221936.2188, 110863.2188,\n",
      "        108983.3906, 129828.9688, 331994.2812, 230585.4375, 161468.2031,\n",
      "        117919.4844, 258691.0000, 204642.9219, 139319.7031, 253426.3594,\n",
      "        202307.6719, 139319.7031, 179802.3281, 345662.6562, 106500.1094,\n",
      "        230585.4375, 224616.3594, 138842.9375, 336182.5625, 184160.8750,\n",
      "        108983.3906, 246452.7344, 230585.4375, 140591.1250,  68123.0469,\n",
      "        128557.5625, 161468.2031, 230585.4375,  66975.6953])\n",
      "tensor([203420.1562, 171266.1562, 310274.9062, 105705.4688, 230585.4375,\n",
      "        160196.7969, 110227.5312, 230585.4375, 226205.6094, 106182.2656,\n",
      "        320410.0312, 230585.4375, 213799.5625, 118078.4062, 230585.4375,\n",
      "        182821.9219, 178248.2500,  63077.9414, 230585.4375, 237630.3594,\n",
      "        203420.1562, 267867.4062, 207543.0312, 331606.4688, 211415.6719,\n",
      "        242017.5469, 140750.0469, 104434.0781, 230585.4375, 298475.6250,\n",
      "        262040.5938, 203848.2969, 118585.9062, 118873.0469, 347658.5312,\n",
      "        108188.7344, 230585.4375, 138525.0781, 251331.0000, 307656.0938,\n",
      "        204642.9219, 304196.0625,  69394.4375, 173173.2656, 181232.6406,\n",
      "        212248.5469, 173014.3438, 171419.9062, 230585.4375, 259938.6719,\n",
      "        208019.8125, 230585.4375, 171425.0781, 160832.5000, 230585.4375,\n",
      "        242003.7031, 248609.6406, 220505.8750, 230585.4375, 308419.3750,\n",
      "        231488.2656, 211097.8281, 129511.1250, 138684.0000])\n",
      "tensor([339854.7812, 207805.1562, 179166.6094, 278482.5000, 318171.8750,\n",
      "        173650.0469, 129670.0625, 138525.0781, 321266.0625, 378139.0312,\n",
      "         92652.4219, 138366.1562, 238484.5625, 258183.7812, 230585.4375,\n",
      "        303668.3438, 336186.2188, 230585.4375, 213163.8594, 253883.0938,\n",
      "        234998.0312, 207026.7969, 363452.5000, 110494.1875, 128080.7969,\n",
      "        250459.0938, 139637.5625, 230585.4375, 233243.1406, 260168.7969,\n",
      "        226682.3906, 212051.3750, 172060.7969, 252531.8438, 342393.8750,\n",
      "        254760.5156, 129829.0000, 230585.4375, 180279.1094])\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "\n",
    "model.eval() # Set model to eval mode\n",
    "\n",
    "with torch.no_grad(): # Deactivate gradients for the following code\n",
    "    for numerical_data,categorical_data0, categorical_data1 in validate_loader:\n",
    "\n",
    "        # Determine prediction of model on dev set\n",
    "        inputs = torch.cat([numerical_data, categorical_data0, categorical_data1],dim=1)\n",
    "        # print(inputs)\n",
    "        # print(inputs[0])\n",
    "        preds = model(inputs)\n",
    "        # print(preds)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "        print(preds)\n",
    "        for pred in preds:\n",
    "            # print(pred)\n",
    "            all_preds.append(classify(pred))\n",
    "        # print(preds)\n",
    "\n",
    "        # # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "        # true_preds += (preds == data_labels).sum()\n",
    "        # num_preds += data_labels.shape[0]\n",
    "\n",
    "# all_preds = np.concatenate(all_preds, axis=0)\n",
    "print(all_preds)\n",
    "np.savetxt(\"predykcje.csv\", all_preds, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
